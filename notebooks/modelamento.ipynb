{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986b99e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GOLD] shape: (10005, 147)\n",
      "[splits] carregados de arquivo.\n",
      "[pipeline] imputer/scaler carregados.\n",
      "\n",
      "=== BASELINE RF (GOLD) ===\n",
      "VAL: {'wr_kg_m2_h': {'R2': 0.9307405554581266, 'MAE': 5.3710211866290645e-08}, 'wm_kg_m2_h': {'R2': 0.9251247772044555, 'MAE': 26756.00187413825}}\n",
      "TST: {'wr_kg_m2_h': {'R2': 0.7555313839613604, 'MAE': 1.0838959098182044e-07}, 'wm_kg_m2_h': {'R2': 0.6977987427390622, 'MAE': 58664.260830891195}}\n",
      "modelo salvo em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\rf_gold_20250818_0826.joblib\n",
      "[SILVER2] shape: (11749, 147)  (use como conjunto de robustez)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Projeto A1 — Starter de Modelagem (carrega do FREEZE_DIR)\n",
    "# ============================================================\n",
    "import os, re, json, joblib, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# -------- paths --------\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "PATH_FEATS_GOLD    = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\")\n",
    "PATH_FEATS_SILVER2 = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_silver2.csv\")  # opcional\n",
    "PATH_SPLITS        = os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\")\n",
    "PATH_IMPUTER       = os.path.join(FREEZE_DIR, \"imputer_gold_median.joblib\")\n",
    "PATH_SCALER        = os.path.join(FREEZE_DIR, \"scaler_gold_standard.joblib\")\n",
    "\n",
    "OUT_MODELS_DIR = os.path.join(FREEZE_DIR, \"models\")\n",
    "os.makedirs(OUT_MODELS_DIR, exist_ok=True)\n",
    "\n",
    "YCOLS = [\"wr_kg_m2_h\",\"wm_kg_m2_h\"]\n",
    "\n",
    "def read_multiheader_csv(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Arquivo não encontrado: {path}\")\n",
    "    dfr = pd.read_csv(path, header=[0,1], engine=\"python\")\n",
    "    df  = dfr.copy()\n",
    "    df.columns = [c for (c,_) in dfr.columns]   # usa linha 1 (nomes)\n",
    "    return df\n",
    "\n",
    "def to_datetime_guess(df):\n",
    "    cand = [c for c in df.columns if re.search(r\"(time|hora|data|date|timestamp|datetime|ts)\", c, re.I)]\n",
    "    for c in cand:\n",
    "        s = pd.to_datetime(df[c], errors=\"coerce\", utc=False)\n",
    "        if s.notna().mean() > 0.9:\n",
    "            return s, c\n",
    "    return None, None\n",
    "\n",
    "# -------- 1) carregar GOLD --------\n",
    "df = read_multiheader_csv(PATH_FEATS_GOLD)\n",
    "assert all(c in df.columns for c in YCOLS), \"Alvos ausentes no GOLD.\"\n",
    "print(f\"[GOLD] shape: {df.shape}\")\n",
    "\n",
    "# -------- 2) criar/ler splits temporais 70/10/20 --------\n",
    "if os.path.exists(PATH_SPLITS):\n",
    "    splits = joblib.load(PATH_SPLITS)\n",
    "    print(\"[splits] carregados de arquivo.\")\n",
    "else:\n",
    "    n = len(df)\n",
    "    idx = np.arange(n)  # assume ordenação temporal já no CSV\n",
    "    train_end = int(0.7*n); val_end = int(0.8*n)\n",
    "    splits = {\n",
    "        \"train\": idx[:train_end].tolist(),\n",
    "        \"val\":   idx[train_end:val_end].tolist(),\n",
    "        \"test\":  idx[val_end:].tolist(),\n",
    "    }\n",
    "    joblib.dump(splits, PATH_SPLITS)\n",
    "    print(\"[splits] criados e salvos.\")\n",
    "\n",
    "# -------- 3) montar X/Y e pipeline (imputer + scaler) --------\n",
    "X_all = df.drop(columns=YCOLS).select_dtypes(include=[np.number])\n",
    "y_all = df[YCOLS].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "idx_tr, idx_va, idx_te = splits[\"train\"], splits[\"val\"], splits[\"test\"]\n",
    "X_tr, X_va, X_te = X_all.iloc[idx_tr], X_all.iloc[idx_va], X_all.iloc[idx_te]\n",
    "y_tr, y_va, y_te = y_all.iloc[idx_tr].values, y_all.iloc[idx_va].values, y_all.iloc[idx_te].values\n",
    "\n",
    "if os.path.exists(PATH_IMPUTER) and os.path.exists(PATH_SCALER):\n",
    "    imp = joblib.load(PATH_IMPUTER)\n",
    "    sc  = joblib.load(PATH_SCALER)\n",
    "    print(\"[pipeline] imputer/scaler carregados.\")\n",
    "else:\n",
    "    imp = SimpleImputer(strategy=\"median\")\n",
    "    sc  = StandardScaler()\n",
    "    X_tr_fit = imp.fit_transform(X_tr)\n",
    "    sc.fit(X_tr_fit)\n",
    "    joblib.dump(imp, PATH_IMPUTER)\n",
    "    joblib.dump(sc,  PATH_SCALER)\n",
    "    print(\"[pipeline] imputer/scaler treinados e salvos.\")\n",
    "\n",
    "X_tr_p = sc.transform(imp.transform(X_tr))\n",
    "X_va_p = sc.transform(imp.transform(X_va))\n",
    "X_te_p = sc.transform(imp.transform(X_te))\n",
    "\n",
    "# -------- 4) baseline rápido (RF multi-alvo) --------\n",
    "model = MultiOutputRegressor(RandomForestRegressor(\n",
    "    n_estimators=400, random_state=42, n_jobs=-1\n",
    "))\n",
    "model.fit(X_tr_p, y_tr)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    out = {}\n",
    "    for i, col in enumerate(YCOLS):\n",
    "        out[col] = {\"R2\": float(r2_score(y_true[:,i], y_pred[:,i])),\n",
    "                    \"MAE\": float(mean_absolute_error(y_true[:,i], y_pred[:,i]))}\n",
    "    return out\n",
    "\n",
    "pred_va = model.predict(X_va_p)\n",
    "pred_te = model.predict(X_te_p)\n",
    "m_val   = metrics(y_va, pred_va)\n",
    "m_test  = metrics(y_te, pred_te)\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "MODEL_PATH = os.path.join(OUT_MODELS_DIR, f\"rf_gold_{ts}.joblib\")\n",
    "joblib.dump({\"model\": model, \"imputer\": imp, \"scaler\": sc,\n",
    "             \"feature_names\": X_all.columns.tolist(),\n",
    "             \"y_names\": YCOLS}, MODEL_PATH)\n",
    "\n",
    "print(\"\\n=== BASELINE RF (GOLD) ===\")\n",
    "print(\"VAL:\", m_val)\n",
    "print(\"TST:\", m_test)\n",
    "print(\"modelo salvo em:\", MODEL_PATH)\n",
    "\n",
    "# -------- (opcional) carregar SILVER2 e repetir apenas se desejar --------\n",
    "if os.path.exists(PATH_FEATS_SILVER2):\n",
    "    df_s2 = read_multiheader_csv(PATH_FEATS_SILVER2)\n",
    "    print(f\"[SILVER2] shape: {df_s2.shape}  (use como conjunto de robustez)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d092afee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tabela salva em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\metrics_splits_gold.csv\n",
      "Modelo utilizado: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\rf_gold_20250818_0826.joblib\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "linhas",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inicio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fim",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R2_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_IQR_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_IQR_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ce36f5c8-5444-4a40-a123-25cfb718db4d",
       "rows": [
        [
         "0",
         "treino",
         "7003",
         "2023-03-01 07:00:00",
         "2024-05-06 16:00:00",
         "0.9810048701778589",
         "1.812961988806191e-08",
         "4.9523953808690724e-09",
         "4.9523953808690724e-09",
         "0.9956176152049384",
         "3960.8908561350686",
         "510.9270276065212",
         "510.9270276065212"
        ],
        [
         "1",
         "validacao",
         "1001",
         "2024-05-06 17:00:00",
         "2024-06-22 00:00:00",
         "0.9307405554581266",
         "1.0203624931567875e-07",
         "5.3710211866290645e-08",
         "0.0938345387315076",
         "0.9251247772044555",
         "55223.64276141897",
         "26756.001874138256",
         "0.0767942545946144"
        ],
        [
         "2",
         "teste",
         "2001",
         "2024-06-22 01:00:00",
         "2024-10-14 10:00:00",
         "0.7555313839613604",
         "1.9253379698107024e-07",
         "1.0838959098182045e-07",
         "0.24391327991121753",
         "0.6977987427390622",
         "99333.18564605634",
         "58664.26083089119",
         "0.20955633389902076"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>linhas</th>\n",
       "      <th>inicio</th>\n",
       "      <th>fim</th>\n",
       "      <th>R2_wr_kg_m2_h</th>\n",
       "      <th>RMSE_wr_kg_m2_h</th>\n",
       "      <th>MAE_wr_kg_m2_h</th>\n",
       "      <th>MAE_IQR_wr_kg_m2_h</th>\n",
       "      <th>R2_wm_kg_m2_h</th>\n",
       "      <th>RMSE_wm_kg_m2_h</th>\n",
       "      <th>MAE_wm_kg_m2_h</th>\n",
       "      <th>MAE_IQR_wm_kg_m2_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>treino</td>\n",
       "      <td>7003</td>\n",
       "      <td>2023-03-01 07:00:00</td>\n",
       "      <td>2024-05-06 16:00:00</td>\n",
       "      <td>0.981005</td>\n",
       "      <td>1.812962e-08</td>\n",
       "      <td>4.952395e-09</td>\n",
       "      <td>4.952395e-09</td>\n",
       "      <td>0.995618</td>\n",
       "      <td>3960.890856</td>\n",
       "      <td>510.927028</td>\n",
       "      <td>510.927028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validacao</td>\n",
       "      <td>1001</td>\n",
       "      <td>2024-05-06 17:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "      <td>0.930741</td>\n",
       "      <td>1.020362e-07</td>\n",
       "      <td>5.371021e-08</td>\n",
       "      <td>9.383454e-02</td>\n",
       "      <td>0.925125</td>\n",
       "      <td>55223.642761</td>\n",
       "      <td>26756.001874</td>\n",
       "      <td>0.076794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teste</td>\n",
       "      <td>2001</td>\n",
       "      <td>2024-06-22 01:00:00</td>\n",
       "      <td>2024-10-14 10:00:00</td>\n",
       "      <td>0.755531</td>\n",
       "      <td>1.925338e-07</td>\n",
       "      <td>1.083896e-07</td>\n",
       "      <td>2.439133e-01</td>\n",
       "      <td>0.697799</td>\n",
       "      <td>99333.185646</td>\n",
       "      <td>58664.260831</td>\n",
       "      <td>0.209556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       split  linhas               inicio                  fim  R2_wr_kg_m2_h  \\\n",
       "0     treino    7003  2023-03-01 07:00:00  2024-05-06 16:00:00       0.981005   \n",
       "1  validacao    1001  2024-05-06 17:00:00  2024-06-22 00:00:00       0.930741   \n",
       "2      teste    2001  2024-06-22 01:00:00  2024-10-14 10:00:00       0.755531   \n",
       "\n",
       "   RMSE_wr_kg_m2_h  MAE_wr_kg_m2_h  MAE_IQR_wr_kg_m2_h  R2_wm_kg_m2_h  \\\n",
       "0     1.812962e-08    4.952395e-09        4.952395e-09       0.995618   \n",
       "1     1.020362e-07    5.371021e-08        9.383454e-02       0.925125   \n",
       "2     1.925338e-07    1.083896e-07        2.439133e-01       0.697799   \n",
       "\n",
       "   RMSE_wm_kg_m2_h  MAE_wm_kg_m2_h  MAE_IQR_wm_kg_m2_h  \n",
       "0      3960.890856      510.927028          510.927028  \n",
       "1     55223.642761    26756.001874            0.076794  \n",
       "2     99333.185646    58664.260831            0.209556  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TABELA DE MÉTRICAS POR SPLIT (GOLD) - AUTOSSUFICIENTE (fix RMSE)\n",
    "# ============================================================\n",
    "import os, joblib, numpy as np, pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import iqr\n",
    "\n",
    "# -------- paths --------\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "PATH_FEATS_GOLD = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\")\n",
    "PATH_SPLITS     = os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\")\n",
    "MODELS_DIR      = os.path.join(FREEZE_DIR, \"models\")\n",
    "\n",
    "# pega o modelo mais recente por data de modificação\n",
    "model_file = max(\n",
    "    [os.path.join(MODELS_DIR, f) for f in os.listdir(MODELS_DIR) if f.endswith(\".joblib\")],\n",
    "    key=lambda p: os.path.getmtime(p)\n",
    ")\n",
    "\n",
    "YCOLS = [\"wr_kg_m2_h\",\"wm_kg_m2_h\"]\n",
    "\n",
    "# -------- carregar dados --------\n",
    "df_raw = pd.read_csv(PATH_FEATS_GOLD, header=[0,1], engine=\"python\")\n",
    "df = df_raw.copy()\n",
    "df.columns = [c for (c,_) in df_raw.columns]   # usa só a linha 1 (nomes)\n",
    "\n",
    "X_all = df.drop(columns=YCOLS).select_dtypes(include=[np.number])\n",
    "y_all = df[YCOLS].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "\n",
    "# Coluna temporal (primeira, 'timestamp')\n",
    "tempo_col = pd.to_datetime(df.iloc[:,0], errors=\"coerce\")\n",
    "\n",
    "# -------- carregar splits + modelo/pipeline --------\n",
    "splits = joblib.load(PATH_SPLITS)\n",
    "pack   = joblib.load(model_file)\n",
    "model  = pack[\"model\"]\n",
    "imp    = pack[\"imputer\"]\n",
    "sc     = pack[\"scaler\"]\n",
    "\n",
    "# -------- preparar X/Y já transformados --------\n",
    "idx_tr, idx_va, idx_te = splits[\"train\"], splits[\"val\"], splits[\"test\"]\n",
    "X_tr_p = sc.transform(imp.transform(X_all.iloc[idx_tr]))\n",
    "X_va_p = sc.transform(imp.transform(X_all.iloc[idx_va]))\n",
    "X_te_p = sc.transform(imp.transform(X_all.iloc[idx_te]))\n",
    "y_tr, y_va, y_te = y_all[idx_tr], y_all[idx_va], y_all[idx_te]\n",
    "\n",
    "# -------- funções de métricas --------\n",
    "def mae_iqr(y_true, y_pred):\n",
    "    e = np.abs(y_true - y_pred)\n",
    "    denom = iqr(y_true) or 1.0\n",
    "    return float(np.mean(e) / denom)\n",
    "\n",
    "def resumo_split(nome, idx, y, pred, tempo_col):\n",
    "    r = {\"split\": nome, \"linhas\": len(idx)}\n",
    "    s = tempo_col.iloc[idx]\n",
    "    r[\"inicio\"] = str(pd.to_datetime(s.min()))\n",
    "    r[\"fim\"]    = str(pd.to_datetime(s.max()))\n",
    "    for j, alvo in enumerate(YCOLS):\n",
    "        yt, yp = y[:,j], pred[:,j]\n",
    "        r[f\"R2_{alvo}\"]       = float(r2_score(yt, yp))\n",
    "        r[f\"RMSE_{alvo}\"]     = float(mean_squared_error(yt, yp) ** 0.5)  # <= sem 'squared'\n",
    "        r[f\"MAE_{alvo}\"]      = float(mean_absolute_error(yt, yp))\n",
    "        r[f\"MAE_IQR_{alvo}\"]  = mae_iqr(yt, yp)\n",
    "    return r\n",
    "\n",
    "# -------- gerar previsões --------\n",
    "pred_tr = model.predict(X_tr_p)\n",
    "pred_va = model.predict(X_va_p)\n",
    "pred_te = model.predict(X_te_p)\n",
    "\n",
    "# -------- montar tabela --------\n",
    "res = []\n",
    "res.append(resumo_split(\"treino\", idx_tr, y_tr, pred_tr, tempo_col))\n",
    "res.append(resumo_split(\"validacao\", idx_va, y_va, pred_va, tempo_col))\n",
    "res.append(resumo_split(\"teste\", idx_te, y_te, pred_te, tempo_col))\n",
    "df_res = pd.DataFrame(res)\n",
    "\n",
    "# -------- salvar e mostrar --------\n",
    "out_csv = os.path.join(FREEZE_DIR, \"metrics_splits_gold.csv\")\n",
    "df_res.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Tabela salva em:\", out_csv)\n",
    "print(\"Modelo utilizado:\", model_file)\n",
    "\n",
    "import IPython.display as disp\n",
    "disp.display(df_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3092b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saídas geradas:\n",
      " - C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\metrics_splits_gold.csv\n",
      " - C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\metrics_splits_silver2.csv\n",
      " - C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\metrics_splits_gold_silver2.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "linhas",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inicio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fim",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R2_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_IQR_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_IQR_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b075d17d-ac7a-4dc8-a6e9-85d3b84a3f76",
       "rows": [
        [
         "0",
         "GOLD",
         "treino",
         "7003",
         "2023-03-01 07:00:00",
         "2024-05-06 16:00:00",
         "0.9810048701778589",
         "1.812961988806191e-08",
         "4.9523953808690724e-09",
         "4.9523953808690724e-09",
         "0.9956176152049384",
         "3960.89085613507",
         "510.92702760652134",
         "510.92702760652134"
        ],
        [
         "1",
         "GOLD",
         "validacao",
         "1001",
         "2024-05-06 17:00:00",
         "2024-06-22 00:00:00",
         "0.9307405554581266",
         "1.0203624931567875e-07",
         "5.3710211866290645e-08",
         "0.0938345387315076",
         "0.9251247772044555",
         "55223.64276141897",
         "26756.001874138256",
         "0.0767942545946144"
        ],
        [
         "2",
         "GOLD",
         "teste",
         "2001",
         "2024-06-22 01:00:00",
         "2024-10-14 10:00:00",
         "0.7555313839613604",
         "1.9253379698107024e-07",
         "1.0838959098182045e-07",
         "0.24391327991121753",
         "0.6977987427390622",
         "99333.18564605634",
         "58664.260830891195",
         "0.20955633389902079"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>linhas</th>\n",
       "      <th>inicio</th>\n",
       "      <th>fim</th>\n",
       "      <th>R2_wr_kg_m2_h</th>\n",
       "      <th>RMSE_wr_kg_m2_h</th>\n",
       "      <th>MAE_wr_kg_m2_h</th>\n",
       "      <th>MAE_IQR_wr_kg_m2_h</th>\n",
       "      <th>R2_wm_kg_m2_h</th>\n",
       "      <th>RMSE_wm_kg_m2_h</th>\n",
       "      <th>MAE_wm_kg_m2_h</th>\n",
       "      <th>MAE_IQR_wm_kg_m2_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOLD</td>\n",
       "      <td>treino</td>\n",
       "      <td>7003</td>\n",
       "      <td>2023-03-01 07:00:00</td>\n",
       "      <td>2024-05-06 16:00:00</td>\n",
       "      <td>0.981005</td>\n",
       "      <td>1.812962e-08</td>\n",
       "      <td>4.952395e-09</td>\n",
       "      <td>4.952395e-09</td>\n",
       "      <td>0.995618</td>\n",
       "      <td>3960.890856</td>\n",
       "      <td>510.927028</td>\n",
       "      <td>510.927028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOLD</td>\n",
       "      <td>validacao</td>\n",
       "      <td>1001</td>\n",
       "      <td>2024-05-06 17:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "      <td>0.930741</td>\n",
       "      <td>1.020362e-07</td>\n",
       "      <td>5.371021e-08</td>\n",
       "      <td>9.383454e-02</td>\n",
       "      <td>0.925125</td>\n",
       "      <td>55223.642761</td>\n",
       "      <td>26756.001874</td>\n",
       "      <td>0.076794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOLD</td>\n",
       "      <td>teste</td>\n",
       "      <td>2001</td>\n",
       "      <td>2024-06-22 01:00:00</td>\n",
       "      <td>2024-10-14 10:00:00</td>\n",
       "      <td>0.755531</td>\n",
       "      <td>1.925338e-07</td>\n",
       "      <td>1.083896e-07</td>\n",
       "      <td>2.439133e-01</td>\n",
       "      <td>0.697799</td>\n",
       "      <td>99333.185646</td>\n",
       "      <td>58664.260831</td>\n",
       "      <td>0.209556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset      split  linhas               inicio                  fim  \\\n",
       "0    GOLD     treino    7003  2023-03-01 07:00:00  2024-05-06 16:00:00   \n",
       "1    GOLD  validacao    1001  2024-05-06 17:00:00  2024-06-22 00:00:00   \n",
       "2    GOLD      teste    2001  2024-06-22 01:00:00  2024-10-14 10:00:00   \n",
       "\n",
       "   R2_wr_kg_m2_h  RMSE_wr_kg_m2_h  MAE_wr_kg_m2_h  MAE_IQR_wr_kg_m2_h  \\\n",
       "0       0.981005     1.812962e-08    4.952395e-09        4.952395e-09   \n",
       "1       0.930741     1.020362e-07    5.371021e-08        9.383454e-02   \n",
       "2       0.755531     1.925338e-07    1.083896e-07        2.439133e-01   \n",
       "\n",
       "   R2_wm_kg_m2_h  RMSE_wm_kg_m2_h  MAE_wm_kg_m2_h  MAE_IQR_wm_kg_m2_h  \n",
       "0       0.995618      3960.890856      510.927028          510.927028  \n",
       "1       0.925125     55223.642761    26756.001874            0.076794  \n",
       "2       0.697799     99333.185646    58664.260831            0.209556  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dataset",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "linhas",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inicio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fim",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R2_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_IQR_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_IQR_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0da8f8d3-da39-4112-9872-3f0a7b6e1d63",
       "rows": [
        [
         "0",
         "SILVER2",
         "treino",
         "8224",
         "2023-03-01 07:00:00",
         "2024-07-02 04:00:00",
         "0.8817880929841891",
         "5.396967413352474e-08",
         "1.6293709560409035e-08",
         "530.7841979535077",
         "0.9548855193495038",
         "19377.270121365153",
         "4729.75917061283",
         "732.9173857216581"
        ],
        [
         "1",
         "SILVER2",
         "validacao",
         "1175",
         "2024-07-02 05:00:00",
         "2024-08-20 03:00:00",
         "0.5610531221736086",
         "1.768686686432507e-07",
         "9.370144111445002e-08",
         "0.2687936283408233",
         "0.8224853464807957",
         "63210.1298740677",
         "34975.88297630405",
         "0.14310307048912022"
        ],
        [
         "2",
         "SILVER2",
         "teste",
         "2350",
         "2024-08-20 04:00:00",
         "2024-12-27 01:00:00",
         "-0.4458206904760911",
         "3.5792653836012174e-07",
         "2.2429629947026738e-07",
         "0.7638825919077905",
         "0.6210592999717119",
         "93712.91844730361",
         "66286.95548728798",
         "0.30828131020161814"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>linhas</th>\n",
       "      <th>inicio</th>\n",
       "      <th>fim</th>\n",
       "      <th>R2_wr_kg_m2_h</th>\n",
       "      <th>RMSE_wr_kg_m2_h</th>\n",
       "      <th>MAE_wr_kg_m2_h</th>\n",
       "      <th>MAE_IQR_wr_kg_m2_h</th>\n",
       "      <th>R2_wm_kg_m2_h</th>\n",
       "      <th>RMSE_wm_kg_m2_h</th>\n",
       "      <th>MAE_wm_kg_m2_h</th>\n",
       "      <th>MAE_IQR_wm_kg_m2_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SILVER2</td>\n",
       "      <td>treino</td>\n",
       "      <td>8224</td>\n",
       "      <td>2023-03-01 07:00:00</td>\n",
       "      <td>2024-07-02 04:00:00</td>\n",
       "      <td>0.881788</td>\n",
       "      <td>5.396967e-08</td>\n",
       "      <td>1.629371e-08</td>\n",
       "      <td>530.784198</td>\n",
       "      <td>0.954886</td>\n",
       "      <td>19377.270121</td>\n",
       "      <td>4729.759171</td>\n",
       "      <td>732.917386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SILVER2</td>\n",
       "      <td>validacao</td>\n",
       "      <td>1175</td>\n",
       "      <td>2024-07-02 05:00:00</td>\n",
       "      <td>2024-08-20 03:00:00</td>\n",
       "      <td>0.561053</td>\n",
       "      <td>1.768687e-07</td>\n",
       "      <td>9.370144e-08</td>\n",
       "      <td>0.268794</td>\n",
       "      <td>0.822485</td>\n",
       "      <td>63210.129874</td>\n",
       "      <td>34975.882976</td>\n",
       "      <td>0.143103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SILVER2</td>\n",
       "      <td>teste</td>\n",
       "      <td>2350</td>\n",
       "      <td>2024-08-20 04:00:00</td>\n",
       "      <td>2024-12-27 01:00:00</td>\n",
       "      <td>-0.445821</td>\n",
       "      <td>3.579265e-07</td>\n",
       "      <td>2.242963e-07</td>\n",
       "      <td>0.763883</td>\n",
       "      <td>0.621059</td>\n",
       "      <td>93712.918447</td>\n",
       "      <td>66286.955487</td>\n",
       "      <td>0.308281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset      split  linhas               inicio                  fim  \\\n",
       "0  SILVER2     treino    8224  2023-03-01 07:00:00  2024-07-02 04:00:00   \n",
       "1  SILVER2  validacao    1175  2024-07-02 05:00:00  2024-08-20 03:00:00   \n",
       "2  SILVER2      teste    2350  2024-08-20 04:00:00  2024-12-27 01:00:00   \n",
       "\n",
       "   R2_wr_kg_m2_h  RMSE_wr_kg_m2_h  MAE_wr_kg_m2_h  MAE_IQR_wr_kg_m2_h  \\\n",
       "0       0.881788     5.396967e-08    1.629371e-08          530.784198   \n",
       "1       0.561053     1.768687e-07    9.370144e-08            0.268794   \n",
       "2      -0.445821     3.579265e-07    2.242963e-07            0.763883   \n",
       "\n",
       "   R2_wm_kg_m2_h  RMSE_wm_kg_m2_h  MAE_wm_kg_m2_h  MAE_IQR_wm_kg_m2_h  \n",
       "0       0.954886     19377.270121     4729.759171          732.917386  \n",
       "1       0.822485     63210.129874    34975.882976            0.143103  \n",
       "2       0.621059     93712.918447    66286.955487            0.308281  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MÉTRICAS POR SPLIT — GOLD e SILVER2 (comparativo)\n",
    "# Usa o modelo/pipeline treinado no GOLD\n",
    "# ============================================================\n",
    "import os, joblib, numpy as np, pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import iqr\n",
    "\n",
    "# -------- paths --------\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "PATH_FEATS_GOLD    = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\")\n",
    "PATH_FEATS_SILVER2 = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_silver2.csv\")\n",
    "PATH_SPLITS_GOLD   = os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\")\n",
    "MODELS_DIR         = os.path.join(FREEZE_DIR, \"models\")\n",
    "\n",
    "# modelo mais recente\n",
    "model_file = max(\n",
    "    [os.path.join(MODELS_DIR, f) for f in os.listdir(MODELS_DIR) if f.endswith(\".joblib\")],\n",
    "    key=lambda p: os.path.getmtime(p)\n",
    ")\n",
    "\n",
    "YCOLS = [\"wr_kg_m2_h\",\"wm_kg_m2_h\"]\n",
    "\n",
    "def mae_iqr(y_true, y_pred):\n",
    "    e = np.abs(y_true - y_pred)\n",
    "    denom = iqr(y_true) or 1.0\n",
    "    return float(np.mean(e) / denom)\n",
    "\n",
    "def resumo_split(dataset, nome, idx, y, pred, tempo_col):\n",
    "    r = {\"dataset\": dataset, \"split\": nome, \"linhas\": len(idx)}\n",
    "    s = tempo_col.iloc[idx]\n",
    "    r[\"inicio\"] = str(pd.to_datetime(s.min()))\n",
    "    r[\"fim\"]    = str(pd.to_datetime(s.max()))\n",
    "    for j, alvo in enumerate(YCOLS):\n",
    "        yt, yp = y[:,j], pred[:,j]\n",
    "        r[f\"R2_{alvo}\"]       = float(r2_score(yt, yp))\n",
    "        r[f\"RMSE_{alvo}\"]     = float(mean_squared_error(yt, yp) ** 0.5)\n",
    "        r[f\"MAE_{alvo}\"]      = float(mean_absolute_error(yt, yp))\n",
    "        r[f\"MAE_IQR_{alvo}\"]  = mae_iqr(yt, yp)\n",
    "    return r\n",
    "\n",
    "def carrega_df(path_csv):\n",
    "    dfr = pd.read_csv(path_csv, header=[0,1], engine=\"python\")\n",
    "    df  = dfr.copy()\n",
    "    df.columns = [c for (c,_) in dfr.columns]   # usa 1ª linha (nomes)\n",
    "    # tempo = primeira coluna (timestamp)\n",
    "    tempo_col = pd.to_datetime(df.iloc[:,0], errors=\"coerce\")\n",
    "    X_all = df.drop(columns=YCOLS).select_dtypes(include=[np.number])\n",
    "    y_all = df[YCOLS].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "    return df, tempo_col, X_all, y_all\n",
    "\n",
    "def split_701020(n):\n",
    "    idx = np.arange(n)\n",
    "    train_end = int(0.7*n); val_end = int(0.8*n)\n",
    "    return idx[:train_end], idx[train_end:val_end], idx[val_end:]\n",
    "\n",
    "# -------- carrega modelo/pipeline (GOLD) --------\n",
    "pack   = joblib.load(model_file)\n",
    "model  = pack[\"model\"]\n",
    "imp    = pack[\"imputer\"]\n",
    "sc     = pack[\"scaler\"]\n",
    "\n",
    "# =================== GOLD ===================\n",
    "df_g, tempo_g, Xg_all, yg_all = carrega_df(PATH_FEATS_GOLD)\n",
    "if os.path.exists(PATH_SPLITS_GOLD):\n",
    "    splits_g = joblib.load(PATH_SPLITS_GOLD)\n",
    "    idxg_tr, idxg_va, idxg_te = splits_g[\"train\"], splits_g[\"val\"], splits_g[\"test\"]\n",
    "else:\n",
    "    idxg_tr, idxg_va, idxg_te = split_701020(len(df_g))\n",
    "\n",
    "Xg_tr_p = sc.transform(imp.transform(Xg_all.iloc[idxg_tr]))\n",
    "Xg_va_p = sc.transform(imp.transform(Xg_all.iloc[idxg_va]))\n",
    "Xg_te_p = sc.transform(imp.transform(Xg_all.iloc[idxg_te]))\n",
    "yg_tr, yg_va, yg_te = yg_all[idxg_tr], yg_all[idxg_va], yg_all[idxg_te]\n",
    "\n",
    "predg_tr = model.predict(Xg_tr_p)\n",
    "predg_va = model.predict(Xg_va_p)\n",
    "predg_te = model.predict(Xg_te_p)\n",
    "\n",
    "rows_gold = []\n",
    "rows_gold.append(resumo_split(\"GOLD\", \"treino\",    idxg_tr, yg_tr, predg_tr, tempo_g))\n",
    "rows_gold.append(resumo_split(\"GOLD\", \"validacao\", idxg_va, yg_va, predg_va, tempo_g))\n",
    "rows_gold.append(resumo_split(\"GOLD\", \"teste\",     idxg_te, yg_te, predg_te, tempo_g))\n",
    "df_gold = pd.DataFrame(rows_gold)\n",
    "\n",
    "# =================== SILVER2 ===================\n",
    "if os.path.exists(PATH_FEATS_SILVER2):\n",
    "    df_s, tempo_s, Xs_all, ys_all = carrega_df(PATH_FEATS_SILVER2)\n",
    "    idxs_tr, idxs_va, idxs_te = split_701020(len(df_s))  # split próprio do SILVER2\n",
    "\n",
    "    Xs_tr_p = sc.transform(imp.transform(Xs_all.iloc[idxs_tr]))\n",
    "    Xs_va_p = sc.transform(imp.transform(Xs_all.iloc[idxs_va]))\n",
    "    Xs_te_p = sc.transform(imp.transform(Xs_all.iloc[idxs_te]))\n",
    "    ys_tr, ys_va, ys_te = ys_all[idxs_tr], ys_all[idxs_va], ys_all[idxs_te]\n",
    "\n",
    "    preds_tr = model.predict(Xs_tr_p)\n",
    "    preds_va = model.predict(Xs_va_p)\n",
    "    preds_te = model.predict(Xs_te_p)\n",
    "\n",
    "    rows_silver = []\n",
    "    rows_silver.append(resumo_split(\"SILVER2\", \"treino\",    idxs_tr, ys_tr, preds_tr, tempo_s))\n",
    "    rows_silver.append(resumo_split(\"SILVER2\", \"validacao\", idxs_va, ys_va, preds_va, tempo_s))\n",
    "    rows_silver.append(resumo_split(\"SILVER2\", \"teste\",     idxs_te, ys_te, preds_te, tempo_s))\n",
    "    df_silver = pd.DataFrame(rows_silver)\n",
    "else:\n",
    "    df_silver = pd.DataFrame(columns=[\"dataset\",\"split\",\"linhas\",\"inicio\",\"fim\"] +\n",
    "        [m for y in YCOLS for m in (f\"R2_{y}\",f\"RMSE_{y}\",f\"MAE_{y}\",f\"MAE_IQR_{y}\")])\n",
    "\n",
    "# -------- salvar saídas --------\n",
    "csv_gold       = os.path.join(FREEZE_DIR, \"metrics_splits_gold.csv\")\n",
    "csv_silver2    = os.path.join(FREEZE_DIR, \"metrics_splits_silver2.csv\")\n",
    "csv_comparado  = os.path.join(FREEZE_DIR, \"metrics_splits_gold_silver2.csv\")\n",
    "\n",
    "df_gold.to_csv(csv_gold, index=False, encoding=\"utf-8\")\n",
    "df_silver.to_csv(csv_silver2, index=False, encoding=\"utf-8\") if not df_silver.empty else None\n",
    "pd.concat([df_gold, df_silver], axis=0, ignore_index=True).to_csv(csv_comparado, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saídas geradas:\")\n",
    "print(\" -\", csv_gold)\n",
    "if not df_silver.empty:\n",
    "    print(\" -\", csv_silver2)\n",
    "    print(\" -\", csv_comparado)\n",
    "else:\n",
    "    print(\" - SILVER2 não encontrado ou vazio; gerado apenas GOLD.\")\n",
    "\n",
    "import IPython.display as disp\n",
    "disp.display(df_gold)\n",
    "if not df_silver.empty:\n",
    "    disp.display(df_silver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31316de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Utilidades para loader, métricas e resumo por split (GOLD)\n",
    "# ============================================================\n",
    "import os, joblib, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import iqr\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "PATH_FEATS_GOLD = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\")\n",
    "PATH_SPLITS     = os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\")\n",
    "PATH_IMPUTER    = os.path.join(FREEZE_DIR, \"imputer_gold_median.joblib\")\n",
    "PATH_SCALER     = os.path.join(FREEZE_DIR, \"scaler_gold_standard.joblib\")\n",
    "\n",
    "os.makedirs(os.path.join(FREEZE_DIR, \"models\"), exist_ok=True)\n",
    "\n",
    "def load_gold_xy(target_col):\n",
    "    # Lê CSV com 2 cabeçalhos, usa só a 1ª linha (nomes)\n",
    "    dfr = pd.read_csv(PATH_FEATS_GOLD, header=[0,1], engine=\"python\")\n",
    "    df  = dfr.copy()\n",
    "    df.columns = [c for (c,_) in dfr.columns]\n",
    "\n",
    "    # timestamp = primeira coluna\n",
    "    tempo_col = pd.to_datetime(df.iloc[:,0], errors=\"coerce\")\n",
    "\n",
    "    # X = numéricas (sem os alvos), y = alvo único\n",
    "    ycols = [\"wr_kg_m2_h\",\"wm_kg_m2_h\"]\n",
    "    if target_col not in ycols:\n",
    "        raise ValueError(f\"Alvo inválido: {target_col}. Use {ycols}.\")\n",
    "    X_all = df.drop(columns=ycols).select_dtypes(include=[np.number])\n",
    "    y_all = pd.to_numeric(df[target_col], errors=\"coerce\").values.reshape(-1, 1)\n",
    "\n",
    "    # splits temporais\n",
    "    splits = joblib.load(PATH_SPLITS)\n",
    "    idx_tr, idx_va, idx_te = splits[\"train\"], splits[\"val\"], splits[\"test\"]\n",
    "\n",
    "    # pipeline (imputer+scaler) do GOLD\n",
    "    imp = joblib.load(PATH_IMPUTER)\n",
    "    sc  = joblib.load(PATH_SCALER)\n",
    "    X_tr_p = sc.transform(imp.transform(X_all.iloc[idx_tr]))\n",
    "    X_va_p = sc.transform(imp.transform(X_all.iloc[idx_va]))\n",
    "    X_te_p = sc.transform(imp.transform(X_all.iloc[idx_te]))\n",
    "    y_tr, y_va, y_te = y_all[idx_tr], y_all[idx_va], y_all[idx_te]\n",
    "\n",
    "    return {\n",
    "        \"df\": df,\n",
    "        \"tempo\": tempo_col,\n",
    "        \"X_tr_p\": X_tr_p, \"X_va_p\": X_va_p, \"X_te_p\": X_te_p,\n",
    "        \"y_tr\": y_tr, \"y_va\": y_va, \"y_te\": y_te,\n",
    "        \"idx_tr\": idx_tr, \"idx_va\": idx_va, \"idx_te\": idx_te,\n",
    "        \"imp\": imp, \"sc\": sc\n",
    "    }\n",
    "\n",
    "def mae_iqr(y_true, y_pred):\n",
    "    e = np.abs(y_true - y_pred).ravel()\n",
    "    denom = iqr(y_true.ravel())\n",
    "    if not np.isfinite(denom) or denom == 0.0:\n",
    "        denom = 1.0\n",
    "    return float(np.mean(e) / denom)\n",
    "\n",
    "def resumo_split(nome, idx, y, pred, tempo_col, alvo_name):\n",
    "    r = {\"split\": nome, \"linhas\": len(idx)}\n",
    "    s = tempo_col.iloc[idx]\n",
    "    r[\"inicio\"] = str(pd.to_datetime(s.min()))\n",
    "    r[\"fim\"]    = str(pd.to_datetime(s.max()))\n",
    "    yt, yp = y.ravel(), pred.ravel()\n",
    "    r[f\"R2_{alvo_name}\"]      = float(r2_score(yt, yp))\n",
    "    r[f\"RMSE_{alvo_name}\"]    = float(mean_squared_error(yt, yp) ** 0.5)\n",
    "    r[f\"MAE_{alvo_name}\"]     = float(mean_absolute_error(yt, yp))\n",
    "    r[f\"MAE_IQR_{alvo_name}\"] = float(mae_iqr(yt, yp))\n",
    "    return r\n",
    "\n",
    "def now_tag():\n",
    "    return datetime.now().strftime(\"%Y%m%d_%H%M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7775893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas Wr salvas em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\metrics_wr_gold.csv\n",
      "Modelo Wr salvo em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\rf_wr_gold_20250818_0826.joblib\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "linhas",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inicio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fim",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R2_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_IQR_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "b99bc0d3-7c8e-4278-9620-45cc391dcecd",
       "rows": [
        [
         "0",
         "treino",
         "7003",
         "2023-03-01 07:00:00",
         "2024-05-06 16:00:00",
         "0.9810048701778589",
         "1.812961988806191e-08",
         "4.9523953808690724e-09",
         "4.9523953808690724e-09"
        ],
        [
         "1",
         "validacao",
         "1001",
         "2024-05-06 17:00:00",
         "2024-06-22 00:00:00",
         "0.9307405554581266",
         "1.0203624931567875e-07",
         "5.371021186629064e-08",
         "0.09383453873150759"
        ],
        [
         "2",
         "teste",
         "2001",
         "2024-06-22 01:00:00",
         "2024-10-14 10:00:00",
         "0.7555313839613604",
         "1.9253379698107024e-07",
         "1.0838959098182045e-07",
         "0.24391327991121753"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>linhas</th>\n",
       "      <th>inicio</th>\n",
       "      <th>fim</th>\n",
       "      <th>R2_wr_kg_m2_h</th>\n",
       "      <th>RMSE_wr_kg_m2_h</th>\n",
       "      <th>MAE_wr_kg_m2_h</th>\n",
       "      <th>MAE_IQR_wr_kg_m2_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>treino</td>\n",
       "      <td>7003</td>\n",
       "      <td>2023-03-01 07:00:00</td>\n",
       "      <td>2024-05-06 16:00:00</td>\n",
       "      <td>0.981005</td>\n",
       "      <td>1.812962e-08</td>\n",
       "      <td>4.952395e-09</td>\n",
       "      <td>4.952395e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validacao</td>\n",
       "      <td>1001</td>\n",
       "      <td>2024-05-06 17:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "      <td>0.930741</td>\n",
       "      <td>1.020362e-07</td>\n",
       "      <td>5.371021e-08</td>\n",
       "      <td>9.383454e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teste</td>\n",
       "      <td>2001</td>\n",
       "      <td>2024-06-22 01:00:00</td>\n",
       "      <td>2024-10-14 10:00:00</td>\n",
       "      <td>0.755531</td>\n",
       "      <td>1.925338e-07</td>\n",
       "      <td>1.083896e-07</td>\n",
       "      <td>2.439133e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       split  linhas               inicio                  fim  R2_wr_kg_m2_h  \\\n",
       "0     treino    7003  2023-03-01 07:00:00  2024-05-06 16:00:00       0.981005   \n",
       "1  validacao    1001  2024-05-06 17:00:00  2024-06-22 00:00:00       0.930741   \n",
       "2      teste    2001  2024-06-22 01:00:00  2024-10-14 10:00:00       0.755531   \n",
       "\n",
       "   RMSE_wr_kg_m2_h  MAE_wr_kg_m2_h  MAE_IQR_wr_kg_m2_h  \n",
       "0     1.812962e-08    4.952395e-09        4.952395e-09  \n",
       "1     1.020362e-07    5.371021e-08        9.383454e-02  \n",
       "2     1.925338e-07    1.083896e-07        2.439133e-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Treino e avaliação: modelo dedicado para Wr (GOLD)\n",
    "# ============================================================\n",
    "import os, joblib, numpy as np, pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "target = \"wr_kg_m2_h\"\n",
    "bundle = load_gold_xy(target)\n",
    "tempo = bundle[\"tempo\"]\n",
    "\n",
    "# Modelo\n",
    "rf_wr = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "rf_wr.fit(bundle[\"X_tr_p\"], bundle[\"y_tr\"].ravel())\n",
    "\n",
    "# Previsões\n",
    "pred_tr = rf_wr.predict(bundle[\"X_tr_p\"]).reshape(-1,1)\n",
    "pred_va = rf_wr.predict(bundle[\"X_va_p\"]).reshape(-1,1)\n",
    "pred_te = rf_wr.predict(bundle[\"X_te_p\"]).reshape(-1,1)\n",
    "\n",
    "# Tabela de métricas\n",
    "rows = []\n",
    "rows.append(resumo_split(\"treino\", bundle[\"idx_tr\"], bundle[\"y_tr\"], pred_tr, tempo, target))\n",
    "rows.append(resumo_split(\"validacao\", bundle[\"idx_va\"], bundle[\"y_va\"], pred_va, tempo, target))\n",
    "rows.append(resumo_split(\"teste\", bundle[\"idx_te\"], bundle[\"y_te\"], pred_te, tempo, target))\n",
    "df_wr = pd.DataFrame(rows)\n",
    "\n",
    "# Salvar métricas e modelo\n",
    "csv_wr = os.path.join(FREEZE_DIR, \"metrics_wr_gold.csv\")\n",
    "df_wr.to_csv(csv_wr, index=False, encoding=\"utf-8\")\n",
    "\n",
    "model_path_wr = os.path.join(FREEZE_DIR, \"models\", f\"rf_wr_gold_{now_tag()}.joblib\")\n",
    "joblib.dump({\n",
    "    \"model\": rf_wr,\n",
    "    \"imputer\": bundle[\"imp\"],\n",
    "    \"scaler\":  bundle[\"sc\"],\n",
    "    \"target\":  target\n",
    "}, model_path_wr)\n",
    "\n",
    "print(\"Métricas Wr salvas em:\", csv_wr)\n",
    "print(\"Modelo Wr salvo em:\", model_path_wr)\n",
    "display(df_wr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fdd95f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas Wm salvas em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\metrics_wm_gold.csv\n",
      "Modelos Wm salvos em:\n",
      " - C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\rf_wm_direct_gold_20250818_0827.joblib\n",
      " - C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\rf_wm_log1p_gold_20250818_0827.joblib\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "variante",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "linhas",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inicio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fim",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R2_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_IQR_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ddfda8f3-b104-41d7-a437-1536ef9d6989",
       "rows": [
        [
         "0",
         "direto",
         "treino",
         "7003",
         "2023-03-01 07:00:00",
         "2024-05-06 16:00:00",
         "0.9956176152049384",
         "3960.890856135069",
         "510.92702760652116",
         "510.92702760652116"
        ],
        [
         "1",
         "direto",
         "validacao",
         "1001",
         "2024-05-06 17:00:00",
         "2024-06-22 00:00:00",
         "0.9251247772044555",
         "55223.64276141896",
         "26756.00187413825",
         "0.07679425459461439"
        ],
        [
         "2",
         "direto",
         "teste",
         "2001",
         "2024-06-22 01:00:00",
         "2024-10-14 10:00:00",
         "0.6977987427390622",
         "99333.18564605634",
         "58664.26083089119",
         "0.20955633389902076"
        ],
        [
         "3",
         "log1p",
         "treino",
         "7003",
         "2023-03-01 07:00:00",
         "2024-05-06 16:00:00",
         "0.9947355441515635",
         "4341.245690805235",
         "535.7080240229928",
         "535.7080240229928"
        ],
        [
         "4",
         "log1p",
         "validacao",
         "1001",
         "2024-05-06 17:00:00",
         "2024-06-22 00:00:00",
         "0.8896783022959468",
         "67032.66028893743",
         "31794.807533271793",
         "0.0912564797977866"
        ],
        [
         "5",
         "log1p",
         "teste",
         "2001",
         "2024-06-22 01:00:00",
         "2024-10-14 10:00:00",
         "0.5343887151230229",
         "123298.5527731541",
         "73682.54004075014",
         "0.26320357138424444"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variante</th>\n",
       "      <th>split</th>\n",
       "      <th>linhas</th>\n",
       "      <th>inicio</th>\n",
       "      <th>fim</th>\n",
       "      <th>R2_wm_kg_m2_h</th>\n",
       "      <th>RMSE_wm_kg_m2_h</th>\n",
       "      <th>MAE_wm_kg_m2_h</th>\n",
       "      <th>MAE_IQR_wm_kg_m2_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>direto</td>\n",
       "      <td>treino</td>\n",
       "      <td>7003</td>\n",
       "      <td>2023-03-01 07:00:00</td>\n",
       "      <td>2024-05-06 16:00:00</td>\n",
       "      <td>0.995618</td>\n",
       "      <td>3960.890856</td>\n",
       "      <td>510.927028</td>\n",
       "      <td>510.927028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>direto</td>\n",
       "      <td>validacao</td>\n",
       "      <td>1001</td>\n",
       "      <td>2024-05-06 17:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "      <td>0.925125</td>\n",
       "      <td>55223.642761</td>\n",
       "      <td>26756.001874</td>\n",
       "      <td>0.076794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>direto</td>\n",
       "      <td>teste</td>\n",
       "      <td>2001</td>\n",
       "      <td>2024-06-22 01:00:00</td>\n",
       "      <td>2024-10-14 10:00:00</td>\n",
       "      <td>0.697799</td>\n",
       "      <td>99333.185646</td>\n",
       "      <td>58664.260831</td>\n",
       "      <td>0.209556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>log1p</td>\n",
       "      <td>treino</td>\n",
       "      <td>7003</td>\n",
       "      <td>2023-03-01 07:00:00</td>\n",
       "      <td>2024-05-06 16:00:00</td>\n",
       "      <td>0.994736</td>\n",
       "      <td>4341.245691</td>\n",
       "      <td>535.708024</td>\n",
       "      <td>535.708024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>log1p</td>\n",
       "      <td>validacao</td>\n",
       "      <td>1001</td>\n",
       "      <td>2024-05-06 17:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "      <td>0.889678</td>\n",
       "      <td>67032.660289</td>\n",
       "      <td>31794.807533</td>\n",
       "      <td>0.091256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>log1p</td>\n",
       "      <td>teste</td>\n",
       "      <td>2001</td>\n",
       "      <td>2024-06-22 01:00:00</td>\n",
       "      <td>2024-10-14 10:00:00</td>\n",
       "      <td>0.534389</td>\n",
       "      <td>123298.552773</td>\n",
       "      <td>73682.540041</td>\n",
       "      <td>0.263204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variante      split  linhas               inicio                  fim  \\\n",
       "0   direto     treino    7003  2023-03-01 07:00:00  2024-05-06 16:00:00   \n",
       "1   direto  validacao    1001  2024-05-06 17:00:00  2024-06-22 00:00:00   \n",
       "2   direto      teste    2001  2024-06-22 01:00:00  2024-10-14 10:00:00   \n",
       "3    log1p     treino    7003  2023-03-01 07:00:00  2024-05-06 16:00:00   \n",
       "4    log1p  validacao    1001  2024-05-06 17:00:00  2024-06-22 00:00:00   \n",
       "5    log1p      teste    2001  2024-06-22 01:00:00  2024-10-14 10:00:00   \n",
       "\n",
       "   R2_wm_kg_m2_h  RMSE_wm_kg_m2_h  MAE_wm_kg_m2_h  MAE_IQR_wm_kg_m2_h  \n",
       "0       0.995618      3960.890856      510.927028          510.927028  \n",
       "1       0.925125     55223.642761    26756.001874            0.076794  \n",
       "2       0.697799     99333.185646    58664.260831            0.209556  \n",
       "3       0.994736      4341.245691      535.708024          535.708024  \n",
       "4       0.889678     67032.660289    31794.807533            0.091256  \n",
       "5       0.534389    123298.552773    73682.540041            0.263204  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Treino e avaliação: modelos dedicados para Wm (direto e log1p)\n",
    "# ============================================================\n",
    "import os, joblib, numpy as np, pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "target = \"wm_kg_m2_h\"\n",
    "bundle = load_gold_xy(target)\n",
    "tempo = bundle[\"tempo\"]\n",
    "\n",
    "# Modelo direto em Wm\n",
    "rf_wm_direct = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "rf_wm_direct.fit(bundle[\"X_tr_p\"], bundle[\"y_tr\"].ravel())\n",
    "\n",
    "pred_tr_dir = rf_wm_direct.predict(bundle[\"X_tr_p\"]).reshape(-1,1)\n",
    "pred_va_dir = rf_wm_direct.predict(bundle[\"X_va_p\"]).reshape(-1,1)\n",
    "pred_te_dir = rf_wm_direct.predict(bundle[\"X_te_p\"]).reshape(-1,1)\n",
    "\n",
    "# Modelo em log1p(Wm)\n",
    "y_tr_log = np.log1p(bundle[\"y_tr\"])\n",
    "rf_wm_log = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "rf_wm_log.fit(bundle[\"X_tr_p\"], y_tr_log.ravel())\n",
    "\n",
    "# previsões no espaço do log e retorno ao original com expm1\n",
    "pred_tr_log = np.expm1(rf_wm_log.predict(bundle[\"X_tr_p\"]).reshape(-1,1))\n",
    "pred_va_log = np.expm1(rf_wm_log.predict(bundle[\"X_va_p\"]).reshape(-1,1))\n",
    "pred_te_log = np.expm1(rf_wm_log.predict(bundle[\"X_te_p\"]).reshape(-1,1))\n",
    "\n",
    "# Tabelas de métricas\n",
    "rows = []\n",
    "rows.append({\"variante\":\"direto\", **resumo_split(\"treino\", bundle[\"idx_tr\"], bundle[\"y_tr\"], pred_tr_dir, tempo, target)})\n",
    "rows.append({\"variante\":\"direto\", **resumo_split(\"validacao\", bundle[\"idx_va\"], bundle[\"y_va\"], pred_va_dir, tempo, target)})\n",
    "rows.append({\"variante\":\"direto\", **resumo_split(\"teste\", bundle[\"idx_te\"], bundle[\"y_te\"], pred_te_dir, tempo, target)})\n",
    "\n",
    "rows.append({\"variante\":\"log1p\", **resumo_split(\"treino\", bundle[\"idx_tr\"], bundle[\"y_tr\"], pred_tr_log, tempo, target)})\n",
    "rows.append({\"variante\":\"log1p\", **resumo_split(\"validacao\", bundle[\"idx_va\"], bundle[\"y_va\"], pred_va_log, tempo, target)})\n",
    "rows.append({\"variante\":\"log1p\", **resumo_split(\"teste\", bundle[\"idx_te\"], bundle[\"y_te\"], pred_te_log, tempo, target)})\n",
    "\n",
    "df_wm = pd.DataFrame(rows)\n",
    "\n",
    "# Salvar métricas e modelos\n",
    "csv_wm = os.path.join(FREEZE_DIR, \"metrics_wm_gold.csv\")\n",
    "df_wm.to_csv(csv_wm, index=False, encoding=\"utf-8\")\n",
    "\n",
    "mp_dir = os.path.join(FREEZE_DIR, \"models\", f\"rf_wm_direct_gold_{now_tag()}.joblib\")\n",
    "mp_log = os.path.join(FREEZE_DIR, \"models\", f\"rf_wm_log1p_gold_{now_tag()}.joblib\")\n",
    "joblib.dump({\"model\": rf_wm_direct, \"imputer\": bundle[\"imp\"], \"scaler\": bundle[\"sc\"], \"target\": target, \"variant\":\"direct\"}, mp_dir)\n",
    "joblib.dump({\"model\": rf_wm_log,    \"imputer\": bundle[\"imp\"], \"scaler\": bundle[\"sc\"], \"target\": target, \"variant\":\"log1p\"}, mp_log)\n",
    "\n",
    "print(\"Métricas Wm salvas em:\", csv_wm)\n",
    "print(\"Modelos Wm salvos em:\")\n",
    "print(\" -\", mp_dir)\n",
    "print(\" -\", mp_log)\n",
    "\n",
    "# Visualização: comparação por split e variante\n",
    "display(df_wm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5219d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidado salvo em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\metrics_wr_wm_gold_consolidado.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_38792\\1719724437.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all = pd.concat([df_wr[cols_order], df_wm[cols_order]], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dataset",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "alvo",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "variante",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "linhas",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inicio",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fim",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R2_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_IQR_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_IQR_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "392d0d5a-36f9-437d-8cb4-7bfd04f8f975",
       "rows": [
        [
         "0",
         "GOLD",
         "wr_kg_m2_h",
         "direto",
         "treino",
         "7003",
         "2023-03-01 07:00:00",
         "2024-05-06 16:00:00",
         "0.9810048701778588",
         "1.812961988806191e-08",
         "4.952395380869072e-09",
         "4.952395380869072e-09",
         null,
         null,
         null,
         null
        ],
        [
         "1",
         "GOLD",
         "wr_kg_m2_h",
         "direto",
         "validacao",
         "1001",
         "2024-05-06 17:00:00",
         "2024-06-22 00:00:00",
         "0.9307405554581266",
         "1.0203624931567877e-07",
         "5.3710211866290645e-08",
         "0.0938345387315075",
         null,
         null,
         null,
         null
        ],
        [
         "2",
         "GOLD",
         "wr_kg_m2_h",
         "direto",
         "teste",
         "2001",
         "2024-06-22 01:00:00",
         "2024-10-14 10:00:00",
         "0.7555313839613604",
         "1.9253379698107024e-07",
         "1.0838959098182045e-07",
         "0.2439132799112175",
         null,
         null,
         null,
         null
        ],
        [
         "3",
         null,
         null,
         "direto",
         "treino",
         "7003",
         "2023-03-01 07:00:00",
         "2024-05-06 16:00:00",
         null,
         null,
         null,
         null,
         "0.9956176152049384",
         "3960.890856135069",
         "510.9270276065212",
         "510.9270276065212"
        ],
        [
         "4",
         null,
         null,
         "direto",
         "validacao",
         "1001",
         "2024-05-06 17:00:00",
         "2024-06-22 00:00:00",
         null,
         null,
         null,
         null,
         "0.9251247772044556",
         "55223.64276141896",
         "26756.00187413825",
         "0.0767942545946143"
        ],
        [
         "5",
         null,
         null,
         "direto",
         "teste",
         "2001",
         "2024-06-22 01:00:00",
         "2024-10-14 10:00:00",
         null,
         null,
         null,
         null,
         "0.6977987427390622",
         "99333.18564605634",
         "58664.26083089119",
         "0.2095563338990207"
        ],
        [
         "6",
         null,
         null,
         "log1p",
         "treino",
         "7003",
         "2023-03-01 07:00:00",
         "2024-05-06 16:00:00",
         null,
         null,
         null,
         null,
         "0.9947355441515636",
         "4341.245690805235",
         "535.7080240229928",
         "535.7080240229928"
        ],
        [
         "7",
         null,
         null,
         "log1p",
         "validacao",
         "1001",
         "2024-05-06 17:00:00",
         "2024-06-22 00:00:00",
         null,
         null,
         null,
         null,
         "0.8896783022959468",
         "67032.66028893743",
         "31794.807533271796",
         "0.0912564797977866"
        ],
        [
         "8",
         null,
         null,
         "log1p",
         "teste",
         "2001",
         "2024-06-22 01:00:00",
         "2024-10-14 10:00:00",
         null,
         null,
         null,
         null,
         "0.5343887151230229",
         "123298.5527731541",
         "73682.54004075014",
         "0.2632035713842444"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>alvo</th>\n",
       "      <th>variante</th>\n",
       "      <th>split</th>\n",
       "      <th>linhas</th>\n",
       "      <th>inicio</th>\n",
       "      <th>fim</th>\n",
       "      <th>R2_wr_kg_m2_h</th>\n",
       "      <th>RMSE_wr_kg_m2_h</th>\n",
       "      <th>MAE_wr_kg_m2_h</th>\n",
       "      <th>MAE_IQR_wr_kg_m2_h</th>\n",
       "      <th>R2_wm_kg_m2_h</th>\n",
       "      <th>RMSE_wm_kg_m2_h</th>\n",
       "      <th>MAE_wm_kg_m2_h</th>\n",
       "      <th>MAE_IQR_wm_kg_m2_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOLD</td>\n",
       "      <td>wr_kg_m2_h</td>\n",
       "      <td>direto</td>\n",
       "      <td>treino</td>\n",
       "      <td>7003</td>\n",
       "      <td>2023-03-01 07:00:00</td>\n",
       "      <td>2024-05-06 16:00:00</td>\n",
       "      <td>0.981005</td>\n",
       "      <td>1.812962e-08</td>\n",
       "      <td>4.952395e-09</td>\n",
       "      <td>4.952395e-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOLD</td>\n",
       "      <td>wr_kg_m2_h</td>\n",
       "      <td>direto</td>\n",
       "      <td>validacao</td>\n",
       "      <td>1001</td>\n",
       "      <td>2024-05-06 17:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "      <td>0.930741</td>\n",
       "      <td>1.020362e-07</td>\n",
       "      <td>5.371021e-08</td>\n",
       "      <td>9.383454e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOLD</td>\n",
       "      <td>wr_kg_m2_h</td>\n",
       "      <td>direto</td>\n",
       "      <td>teste</td>\n",
       "      <td>2001</td>\n",
       "      <td>2024-06-22 01:00:00</td>\n",
       "      <td>2024-10-14 10:00:00</td>\n",
       "      <td>0.755531</td>\n",
       "      <td>1.925338e-07</td>\n",
       "      <td>1.083896e-07</td>\n",
       "      <td>2.439133e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>direto</td>\n",
       "      <td>treino</td>\n",
       "      <td>7003</td>\n",
       "      <td>2023-03-01 07:00:00</td>\n",
       "      <td>2024-05-06 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995618</td>\n",
       "      <td>3960.890856</td>\n",
       "      <td>510.927028</td>\n",
       "      <td>510.927028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>direto</td>\n",
       "      <td>validacao</td>\n",
       "      <td>1001</td>\n",
       "      <td>2024-05-06 17:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925125</td>\n",
       "      <td>55223.642761</td>\n",
       "      <td>26756.001874</td>\n",
       "      <td>0.076794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>direto</td>\n",
       "      <td>teste</td>\n",
       "      <td>2001</td>\n",
       "      <td>2024-06-22 01:00:00</td>\n",
       "      <td>2024-10-14 10:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.697799</td>\n",
       "      <td>99333.185646</td>\n",
       "      <td>58664.260831</td>\n",
       "      <td>0.209556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log1p</td>\n",
       "      <td>treino</td>\n",
       "      <td>7003</td>\n",
       "      <td>2023-03-01 07:00:00</td>\n",
       "      <td>2024-05-06 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994736</td>\n",
       "      <td>4341.245691</td>\n",
       "      <td>535.708024</td>\n",
       "      <td>535.708024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log1p</td>\n",
       "      <td>validacao</td>\n",
       "      <td>1001</td>\n",
       "      <td>2024-05-06 17:00:00</td>\n",
       "      <td>2024-06-22 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889678</td>\n",
       "      <td>67032.660289</td>\n",
       "      <td>31794.807533</td>\n",
       "      <td>0.091256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>log1p</td>\n",
       "      <td>teste</td>\n",
       "      <td>2001</td>\n",
       "      <td>2024-06-22 01:00:00</td>\n",
       "      <td>2024-10-14 10:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534389</td>\n",
       "      <td>123298.552773</td>\n",
       "      <td>73682.540041</td>\n",
       "      <td>0.263204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset        alvo variante      split  linhas               inicio  \\\n",
       "0    GOLD  wr_kg_m2_h   direto     treino    7003  2023-03-01 07:00:00   \n",
       "1    GOLD  wr_kg_m2_h   direto  validacao    1001  2024-05-06 17:00:00   \n",
       "2    GOLD  wr_kg_m2_h   direto      teste    2001  2024-06-22 01:00:00   \n",
       "3     NaN         NaN   direto     treino    7003  2023-03-01 07:00:00   \n",
       "4     NaN         NaN   direto  validacao    1001  2024-05-06 17:00:00   \n",
       "5     NaN         NaN   direto      teste    2001  2024-06-22 01:00:00   \n",
       "6     NaN         NaN    log1p     treino    7003  2023-03-01 07:00:00   \n",
       "7     NaN         NaN    log1p  validacao    1001  2024-05-06 17:00:00   \n",
       "8     NaN         NaN    log1p      teste    2001  2024-06-22 01:00:00   \n",
       "\n",
       "                   fim  R2_wr_kg_m2_h  RMSE_wr_kg_m2_h  MAE_wr_kg_m2_h  \\\n",
       "0  2024-05-06 16:00:00       0.981005     1.812962e-08    4.952395e-09   \n",
       "1  2024-06-22 00:00:00       0.930741     1.020362e-07    5.371021e-08   \n",
       "2  2024-10-14 10:00:00       0.755531     1.925338e-07    1.083896e-07   \n",
       "3  2024-05-06 16:00:00            NaN              NaN             NaN   \n",
       "4  2024-06-22 00:00:00            NaN              NaN             NaN   \n",
       "5  2024-10-14 10:00:00            NaN              NaN             NaN   \n",
       "6  2024-05-06 16:00:00            NaN              NaN             NaN   \n",
       "7  2024-06-22 00:00:00            NaN              NaN             NaN   \n",
       "8  2024-10-14 10:00:00            NaN              NaN             NaN   \n",
       "\n",
       "   MAE_IQR_wr_kg_m2_h  R2_wm_kg_m2_h  RMSE_wm_kg_m2_h  MAE_wm_kg_m2_h  \\\n",
       "0        4.952395e-09            NaN              NaN             NaN   \n",
       "1        9.383454e-02            NaN              NaN             NaN   \n",
       "2        2.439133e-01            NaN              NaN             NaN   \n",
       "3                 NaN       0.995618      3960.890856      510.927028   \n",
       "4                 NaN       0.925125     55223.642761    26756.001874   \n",
       "5                 NaN       0.697799     99333.185646    58664.260831   \n",
       "6                 NaN       0.994736      4341.245691      535.708024   \n",
       "7                 NaN       0.889678     67032.660289    31794.807533   \n",
       "8                 NaN       0.534389    123298.552773    73682.540041   \n",
       "\n",
       "   MAE_IQR_wm_kg_m2_h  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3          510.927028  \n",
       "4            0.076794  \n",
       "5            0.209556  \n",
       "6          535.708024  \n",
       "7            0.091256  \n",
       "8            0.263204  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Consolidação das métricas em um único CSV\n",
    "# ============================================================\n",
    "import os, pandas as pd\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "csv_wr = os.path.join(FREEZE_DIR, \"metrics_wr_gold.csv\")\n",
    "csv_wm = os.path.join(FREEZE_DIR, \"metrics_wm_gold.csv\")\n",
    "\n",
    "df_wr = pd.read_csv(csv_wr)\n",
    "df_wr.insert(0, \"dataset\", \"GOLD\")\n",
    "df_wr.insert(1, \"alvo\", \"wr_kg_m2_h\")\n",
    "df_wr.insert(2, \"variante\", \"direto\")\n",
    "\n",
    "df_wm = pd.read_csv(csv_wm)\n",
    "# df_wm já tem coluna \"variante\" (direto/log1p) e colunas padronizadas\n",
    "\n",
    "cols_order = [\"dataset\",\"alvo\",\"variante\",\"split\",\"linhas\",\"inicio\",\"fim\",\n",
    "              \"R2_wr_kg_m2_h\",\"RMSE_wr_kg_m2_h\",\"MAE_wr_kg_m2_h\",\"MAE_IQR_wr_kg_m2_h\",\n",
    "              \"R2_wm_kg_m2_h\",\"RMSE_wm_kg_m2_h\",\"MAE_wm_kg_m2_h\",\"MAE_IQR_wm_kg_m2_h\"]\n",
    "\n",
    "# alinhar colunas (preencher ausentes com NaN)\n",
    "for c in cols_order:\n",
    "    if c not in df_wr.columns:\n",
    "        df_wr[c] = pd.NA\n",
    "    if c not in df_wm.columns:\n",
    "        df_wm[c] = pd.NA\n",
    "\n",
    "df_all = pd.concat([df_wr[cols_order], df_wm[cols_order]], ignore_index=True)\n",
    "out_csv = os.path.join(FREEZE_DIR, \"metrics_wr_wm_gold_consolidado.csv\")\n",
    "df_all.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Consolidado salvo em:\", out_csv)\n",
    "display(df_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0fc31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "706cd200",
   "metadata": {},
   "source": [
    "Ok — direto ao ponto.\n",
    "\n",
    "# Vale a pena rodar o não supervisionado **agora**?\n",
    "\n",
    "**Sim, com escopo de diagnóstico.** Ele **não** melhora a métrica por si só, mas antecipa decisões de modelagem e evita ciclos inúteis. Dado que a queda de validação→teste indica **shift temporal** (2024-06→2024-10), um diagnóstico não supervisionado agora tende a esclarecer **o que mudou** no teste e **por quê**.\n",
    "\n",
    "---\n",
    "\n",
    "## O que o não supervisionado entrega (e como isso orienta os próximos passos)\n",
    "\n",
    "1. **Mapeamento de regimes (clusters)**\n",
    "\n",
    "   * **O que mostra:** se o bloco de teste contém **regimes novos** ou **sub-representados** no treino.\n",
    "   * **Como usar depois:**\n",
    "\n",
    "     * Definir **especialistas por regime** (modelos por cluster) ou **pesos** no treino.\n",
    "     * Ajustar **backtesting** por regimes (não só por fatia temporal).\n",
    "     * Criar **features** “regime\\_id” (one-hot) e **distância-ao-centróide**.\n",
    "\n",
    "2. **Drift/Shift das distribuições**\n",
    "\n",
    "   * **O que mostra:** quais features mudaram mais entre **treino/val/teste** (PSI/K-S por feature, PCs ao longo do tempo).\n",
    "   * **Como usar depois:**\n",
    "\n",
    "     * Focar engenharia de **lags/janelas** nas variáveis que mais derivam.\n",
    "     * Guiar a escolha de **modelos mais robustos** (ex.: GBMs) e **regularização**.\n",
    "\n",
    "3. **Estrutura latente (PCA/Autoencoders)**\n",
    "\n",
    "   * **O que mostra:** quantas dimensões explicam a maior parte da variância; **combinações físicas** dominantes.\n",
    "   * **Como usar depois:**\n",
    "\n",
    "     * PCA scores como features compactas e estáveis.\n",
    "     * Checar **coerência física** dos loadings e remover ruído/colinearidade residual.\n",
    "\n",
    "4. **Anomalias/Outliers**\n",
    "\n",
    "   * **O que mostra:** pontos raros concentrados no **teste** que puxam erro (IsolationForest/LOF/HDBSCAN ruído).\n",
    "   * **Como usar depois:**\n",
    "\n",
    "     * Estratégias de **robust loss** (Huber/Quantile) ou **capagem** em features.\n",
    "     * Filtragem de janelas degradadas (se forem reais defeitos operacionais e não alvo da previsão).\n",
    "\n",
    "5. **Continuidade temporal dos regimes**\n",
    "\n",
    "   * **O que mostra:** **trocas de cluster ao longo do tempo**, transições e permanência.\n",
    "   * **Como usar depois:**\n",
    "\n",
    "     * Definir **janelas de backtesting** por mudanças de regime (em vez de cortes arbitrários).\n",
    "     * Introduzir **lags** no entorno das transições (onde o erro aumenta).\n",
    "\n",
    "> Restrição importante: manter o **leak-guard** — usar **apenas** features não usadas no cálculo dos rótulos.\n",
    "\n",
    "---\n",
    "\n",
    "## Vantagens de fazer **agora** (antes de novos supervisionados)\n",
    "\n",
    "* **Economiza ciclos:** você alinha o pipeline ao que **de fato** mudou no teste.\n",
    "* **Define CV melhor:** backtesting e/ou *grouped CV* por **regime**, não só por tempo bruto.\n",
    "* **Engenharia de features focada:** cria lags e agregações onde há **drift real**, e não “no escuro”.\n",
    "* **Evita conclusões erradas** do split temporal único (um fold só pode ser “acaso”).\n",
    "\n",
    "## Desvantagens/limitações\n",
    "\n",
    "* **Não melhora a métrica diretamente.** É diagnóstico.\n",
    "* **Clusters podem ser instáveis** se você não fixar semente/método; precisa checar **estabilidade** (variação com sementes e subamostras).\n",
    "* **Risco de “tempo como proxy”:** se padronizar errado, os clusters podem refletir apenas a data. Isso é útil para medir drift, mas ruim como *label* para treinar. Tratar como **sinal de regime**, não como verdade física.\n",
    "\n",
    "---\n",
    "\n",
    "## O que esperar de cada trilha (relacionando com o não supervisionado)\n",
    "\n",
    "* **Manter multi-alvos sem log (baseline atual):**\n",
    "\n",
    "  * Esperado: métricas atuais em linha, mas **erro cresce em regimes novos**.\n",
    "  * Com não supervisionado: você identifica **onde** cresce e **por qual conjunto de variáveis**.\n",
    "\n",
    "* **GBMs para Wm (sem log):**\n",
    "\n",
    "  * Esperado: ganho em **caudas** e interação.\n",
    "  * Com não supervisionado: ajuda a **definir monotonicidades locais** e **features/agrupamentos** que estabilizam o aprendizado.\n",
    "\n",
    "* **Lags/janelas:**\n",
    "\n",
    "  * Esperado: melhora em transições/efeitos de memória.\n",
    "  * Com não supervisionado: você adiciona lags **onde** o cluster muda, não em tudo.\n",
    "\n",
    "* **Backtesting:**\n",
    "\n",
    "  * Esperado: estimativa honesta de generalização.\n",
    "  * Com não supervisionado: folds **alinhados a regimes**, medindo estabilidade **entre clusters** (não só no tempo).\n",
    "\n",
    "---\n",
    "\n",
    "## Sobre “random 70/10/20” para ganhar assertividade\n",
    "\n",
    "* Sim, **melhora a métrica** por amostrar mais regimes no treino — mas **não reflete produção** (sempre futuro não visto).\n",
    "* O uso correto do **random split** aqui é **complementar**: medir **capacidade intrínseca** do modelo, **não** substituir a avaliação temporal.\n",
    "* Se o random subir muito a métrica enquanto o temporal não, isso **confirma drift/regime** e justifica fortemente as ações guiadas pelo não supervisionado.\n",
    "\n",
    "---\n",
    "\n",
    "## Recomendação pragmática\n",
    "\n",
    "Rodar **agora** um **diagnóstico não supervisionado enxuto**, com quatro entregáveis:\n",
    "\n",
    "1. **PCA (padronizado)**: curva de variância explicada; top loadings por componente.\n",
    "2. **Clustering** (KMeans e **HDBSCAN**):\n",
    "\n",
    "   * número de clusters, **silhouette**/DB index;\n",
    "   * **timeline de clusters** e **participação por split** (treino/val/teste).\n",
    "3. **Mapa de drift**: PSI ou K-S **treino vs teste** por feature; ranking das 10 que mais mudaram.\n",
    "4. **Erro por cluster** (usando as **predições já obtidas** do baseline): R²/MAE por cluster e por split.\n",
    "\n",
    "**Critério de decisão depois disso:**\n",
    "\n",
    "* **Novo cluster dominante no teste:** criar **especialista por regime**/pesos e priorizar **lags** das variáveis com maior drift.\n",
    "* **Drift contínuo sem clusters limpos:** priorizar **GBMs com perdas robustas** + **backtesting em janelas**.\n",
    "* **Nada estruturado (clusters fracos, pouco drift):** foco direto em **GBMs** e **otimização de hiperparâmetros**; não gastar mais tempo com regimes.\n",
    "\n",
    "Se concordar, eu preparo as células **diagnóstico-primeiro** (com as suas regras: sem vazamento, barra de progresso, CSVs no `FREEZE_DIR`, e tabelas legíveis).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d365836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: X_all (scaled) salvo, nomes de features salvos e aux.csv salvo.\n",
      "Formas: (10005, 144) | splits: {'train': 7003, 'val': 1001, 'test': 2001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: PREPARAÇÃO (LOAD, SPLITS, PADRONIZAÇÃO)\n",
    "import os, joblib, numpy as np, pandas as pd\n",
    "\n",
    "# Caminhos\n",
    "FREEZE_DIR      = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "PATH_FEATS_GOLD = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\")\n",
    "PATH_SPLITS     = os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\")\n",
    "PATH_IMPUTER    = os.path.join(FREEZE_DIR, \"imputer_gold_median.joblib\")\n",
    "PATH_SCALER     = os.path.join(FREEZE_DIR, \"scaler_gold_standard.joblib\")\n",
    "\n",
    "# Leitura multi-header e redução para nomes\n",
    "dfr = pd.read_csv(PATH_FEATS_GOLD, header=[0,1], engine=\"python\")\n",
    "df  = dfr.copy()\n",
    "df.columns = [c for (c,_) in dfr.columns]\n",
    "\n",
    "# Timestamp é a primeira coluna\n",
    "timestamp = pd.to_datetime(df.iloc[:,0], errors=\"coerce\")\n",
    "\n",
    "# Remove alvos das features\n",
    "YCOLS = [\"wr_kg_m2_h\", \"wm_kg_m2_h\"]\n",
    "X_num = df.drop(columns=YCOLS).select_dtypes(include=[np.number])\n",
    "\n",
    "# Splits e pipeline\n",
    "splits = joblib.load(PATH_SPLITS)\n",
    "imp    = joblib.load(PATH_IMPUTER)\n",
    "sc     = joblib.load(PATH_SCALER)\n",
    "\n",
    "# Aplica imputer+scaler (fitado no treino, já salvo)\n",
    "X_all = sc.transform(imp.transform(X_num.values))\n",
    "\n",
    "# Cria vetor de split por linha\n",
    "n = len(df)\n",
    "lbl = np.array([\"\"]*n, dtype=object)\n",
    "lbl[splits[\"train\"]] = \"train\"\n",
    "lbl[splits[\"val\"]]   = \"val\"\n",
    "lbl[splits[\"test\"]]  = \"test\"\n",
    "\n",
    "# Salva base auxiliar para as próximas etapas\n",
    "aux = pd.DataFrame({\n",
    "    \"timestamp\": timestamp.values,\n",
    "    \"split\": lbl\n",
    "})\n",
    "# Para referência cruzada, mantemos X_all em arquivo numpy e lista de colunas originais\n",
    "np.save(os.path.join(FREEZE_DIR, \"unsup_X_all_scaled.npy\"), X_all)\n",
    "pd.Series(X_num.columns, name=\"feature\").to_csv(os.path.join(FREEZE_DIR, \"unsup_feature_names.csv\"), index=False)\n",
    "aux.to_csv(os.path.join(FREEZE_DIR, \"unsup_aux_gold.csv\"), index=False)\n",
    "\n",
    "print(\"OK: X_all (scaled) salvo, nomes de features salvos e aux.csv salvo.\")\n",
    "print(\"Formas:\", X_all.shape, \"| splits:\", {k:len(v) for k,v in splits.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a205da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: PCA salvo. Arquivos: pca_explained_variance.csv, pca_loadings.csv, pca_scores.csv, pca_variance_curve.png\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: PCA (EXPLAINED VARIANCE, LOADINGS, SCORES)\n",
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "X_all      = np.load(os.path.join(FREEZE_DIR, \"unsup_X_all_scaled.npy\"))\n",
    "aux        = pd.read_csv(os.path.join(FREEZE_DIR, \"unsup_aux_gold.csv\"))\n",
    "feat_names = pd.read_csv(os.path.join(FREEZE_DIR, \"unsup_feature_names.csv\"))[\"feature\"].tolist()\n",
    "\n",
    "# Index dos splits\n",
    "splits     = joblib.load(os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\"))\n",
    "idx_tr     = splits[\"train\"]; idx_va = splits[\"val\"]; idx_te = splits[\"test\"]\n",
    "\n",
    "# PCA ajustado no treino\n",
    "pca = PCA(svd_solver=\"full\", random_state=42)\n",
    "pca.fit(X_all[idx_tr])\n",
    "\n",
    "expl = pd.DataFrame({\n",
    "    \"pc\": np.arange(1, pca.n_components_+1),\n",
    "    \"explained_variance_ratio\": pca.explained_variance_ratio_.ravel()\n",
    "})\n",
    "expl[\"cumulative\"] = expl[\"explained_variance_ratio\"].cumsum()\n",
    "expl.to_csv(os.path.join(FREEZE_DIR, \"pca_explained_variance.csv\"), index=False)\n",
    "\n",
    "# Loadings (componentes x features)\n",
    "loadings = pd.DataFrame(pca.components_, columns=feat_names)\n",
    "loadings.index = [f\"PC{i}\" for i in range(1, pca.n_components_+1)]\n",
    "loadings.to_csv(os.path.join(FREEZE_DIR, \"pca_loadings.csv\"))\n",
    "\n",
    "# Scores (todas as linhas)\n",
    "scores = pca.transform(X_all)\n",
    "pc_cols = [f\"PC{i}\" for i in range(1, scores.shape[1]+1)]\n",
    "df_scores = pd.concat([aux[[\"timestamp\",\"split\"]].reset_index(drop=True),\n",
    "                       pd.DataFrame(scores, columns=pc_cols)], axis=1)\n",
    "df_scores.to_csv(os.path.join(FREEZE_DIR, \"pca_scores.csv\"), index=False)\n",
    "\n",
    "# Gráfico da variância explicada acumulada\n",
    "plt.figure()\n",
    "plt.plot(expl[\"pc\"], expl[\"cumulative\"], marker=\"o\")\n",
    "plt.xlabel(\"Número de Componentes Principais\")\n",
    "plt.ylabel(\"Variância Explicada Acumulada\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "fig_path = os.path.join(FREEZE_DIR, \"pca_variance_curve.png\")\n",
    "plt.savefig(fig_path, dpi=120)\n",
    "plt.close()\n",
    "\n",
    "print(\"OK: PCA salvo. Arquivos: pca_explained_variance.csv, pca_loadings.csv, pca_scores.csv, pca_variance_curve.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1c585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Buscando k (silhouette): 100%|██████████| 9/9 [00:07<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: KMeans concluído. Melhor k=2. Arquivos: kmeans_silhouette_train.csv, kmeans_labels.csv, kmeans_centroids_pcspace.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: KMEANS (SILHOUETTE E ROTULAGEM)\n",
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "scores     = pd.read_csv(os.path.join(FREEZE_DIR, \"pca_scores.csv\"))\n",
    "expl       = pd.read_csv(os.path.join(FREEZE_DIR, \"pca_explained_variance.csv\"))\n",
    "splits     = joblib.load(os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\"))\n",
    "\n",
    "# Seleção de PCs (>=90% variância, máx 20)\n",
    "cum = expl[\"cumulative\"].values\n",
    "n_pcs = int(np.searchsorted(cum, 0.90) + 1)\n",
    "n_pcs = min(max(n_pcs, 2), 20)\n",
    "pc_cols = [f\"PC{i}\" for i in range(1, n_pcs+1)]\n",
    "\n",
    "Xpc = scores[pc_cols].values\n",
    "idx_tr = splits[\"train\"]\n",
    "Xpc_tr = Xpc[idx_tr]\n",
    "\n",
    "# Busca de k pelo silhouette no treino\n",
    "res_k = []\n",
    "for k in tqdm(range(2, 11), desc=\"Buscando k (silhouette)\"):\n",
    "    km = KMeans(n_clusters=k, n_init=\"auto\", random_state=42)\n",
    "    lbl_tr = km.fit_predict(Xpc_tr)\n",
    "    sil = silhouette_score(Xpc_tr, lbl_tr)\n",
    "    res_k.append({\"k\": k, \"silhouette_train\": float(sil)})\n",
    "\n",
    "df_k = pd.DataFrame(res_k).sort_values(\"silhouette_train\", ascending=False)\n",
    "df_k.to_csv(os.path.join(FREEZE_DIR, \"kmeans_silhouette_train.csv\"), index=False)\n",
    "best_k = int(df_k.iloc[0][\"k\"])\n",
    "\n",
    "# Treina KMeans no treino e prediz para todas as linhas\n",
    "km_best = KMeans(n_clusters=best_k, n_init=\"auto\", random_state=42)\n",
    "km_best.fit(Xpc_tr)\n",
    "labels_all = km_best.predict(Xpc)\n",
    "\n",
    "# Salva labels e centróides (em PC-space)\n",
    "out_lbl = scores[[\"timestamp\",\"split\"]].copy()\n",
    "out_lbl[\"kmeans_k\"] = best_k\n",
    "out_lbl[\"cluster\"]  = labels_all\n",
    "out_lbl.to_csv(os.path.join(FREEZE_DIR, \"kmeans_labels.csv\"), index=False)\n",
    "\n",
    "centroids = pd.DataFrame(km_best.cluster_centers_, columns=pc_cols)\n",
    "centroids.insert(0, \"cluster\", np.arange(best_k))\n",
    "centroids.to_csv(os.path.join(FREEZE_DIR, \"kmeans_centroids_pcspace.csv\"), index=False)\n",
    "\n",
    "print(f\"OK: KMeans concluído. Melhor k={best_k}. Arquivos: kmeans_silhouette_train.csv, kmeans_labels.csv, kmeans_centroids_pcspace.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1a660e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdbscan in c:\\users\\wilso\\mba_empreendedorismo\\3agd\\a1_local_refazimento\\.venv\\lib\\site-packages (0.8.40)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\wilso\\mba_empreendedorismo\\3agd\\a1_local_refazimento\\.venv\\lib\\site-packages (from hdbscan) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\wilso\\mba_empreendedorismo\\3agd\\a1_local_refazimento\\.venv\\lib\\site-packages (from hdbscan) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\wilso\\mba_empreendedorismo\\3agd\\a1_local_refazimento\\.venv\\lib\\site-packages (from hdbscan) (1.7.1)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\wilso\\mba_empreendedorismo\\3agd\\a1_local_refazimento\\.venv\\lib\\site-packages (from hdbscan) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\wilso\\mba_empreendedorismo\\3agd\\a1_local_refazimento\\.venv\\lib\\site-packages (from scikit-learn>=0.20->hdbscan) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac26405d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: HDBSCAN concluído. Arquivos: hdbscan_labels.csv, hdbscan_summary_counts.csv\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: HDBSCAN (OPCIONAL)\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "scores     = pd.read_csv(os.path.join(FREEZE_DIR, \"pca_scores.csv\"))\n",
    "expl       = pd.read_csv(os.path.join(FREEZE_DIR, \"pca_explained_variance.csv\"))\n",
    "\n",
    "# Seleção de PCs (>=90% variância, máx 20)\n",
    "cum = expl[\"cumulative\"].values\n",
    "n_pcs = int(np.searchsorted(cum, 0.90) + 1)\n",
    "n_pcs = min(max(n_pcs, 2), 20)\n",
    "pc_cols = [f\"PC{i}\" for i in range(1, n_pcs+1)]\n",
    "Xpc = scores[pc_cols].values\n",
    "\n",
    "try:\n",
    "    import hdbscan\n",
    "    min_cluster_size = max(20, int(0.005 * len(Xpc)))\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=None)\n",
    "    clusterer.fit(Xpc)\n",
    "    labels = clusterer.labels_\n",
    "    probs  = clusterer.probabilities_\n",
    "\n",
    "    out = scores[[\"timestamp\",\"split\"]].copy()\n",
    "    out[\"hdbscan_label\"] = labels\n",
    "    out[\"hdbscan_prob\"]  = probs\n",
    "    out.to_csv(os.path.join(FREEZE_DIR, \"hdbscan_labels.csv\"), index=False)\n",
    "\n",
    "    # Resumo por split\n",
    "    summary = out.groupby([\"split\",\"hdbscan_label\"]).size().reset_index(name=\"count\")\n",
    "    summary.to_csv(os.path.join(FREEZE_DIR, \"hdbscan_summary_counts.csv\"), index=False)\n",
    "    print(\"OK: HDBSCAN concluído. Arquivos: hdbscan_labels.csv, hdbscan_summary_counts.csv\")\n",
    "except Exception as e:\n",
    "    print(\"HDBSCAN não disponível ou falhou. Pule esta etapa ou instale 'hdbscan'. Motivo:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "063b0521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PSI/KS por feature: 100%|██████████| 144/144 [00:22<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Drift salvo em drift_psi_ks_train_vs_test.csv (ordenado por maior PSI/KS).\n"
     ]
    }
   ],
   "source": [
    "# ETAPA: DRIFT (PSI E KS)\n",
    "import os, numpy as np, pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "from tqdm import tqdm\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "X_all      = np.load(os.path.join(FREEZE_DIR, \"unsup_X_all_scaled.npy\"))\n",
    "aux        = pd.read_csv(os.path.join(FREEZE_DIR, \"unsup_aux_gold.csv\"))\n",
    "feat_names = pd.read_csv(os.path.join(FREEZE_DIR, \"unsup_feature_names.csv\"))[\"feature\"].tolist()\n",
    "\n",
    "# Máscaras\n",
    "mask_tr = (aux[\"split\"]==\"train\").values\n",
    "mask_te = (aux[\"split\"]==\"test\").values\n",
    "\n",
    "def psi_from_bins(train_vals, test_vals, bins):\n",
    "    # Distribuições\n",
    "    tr_hist, _ = np.histogram(train_vals, bins=bins)\n",
    "    te_hist, _ = np.histogram(test_vals,  bins=bins)\n",
    "    tr_p = tr_hist / max(tr_hist.sum(), 1)\n",
    "    te_p = te_hist / max(te_hist.sum(), 1)\n",
    "    # Evita zeros\n",
    "    tr_p = np.clip(tr_p, 1e-6, None)\n",
    "    te_p = np.clip(te_p, 1e-6, None)\n",
    "    # PSI\n",
    "    return float(np.sum((tr_p - te_p) * np.log(tr_p / te_p)))\n",
    "\n",
    "rows = []\n",
    "# Bins por quantis do treino (10 bins)\n",
    "for j in tqdm(range(X_all.shape[1]), desc=\"PSI/KS por feature\"):\n",
    "    tr = X_all[mask_tr, j]\n",
    "    te = X_all[mask_te, j]\n",
    "    # quantis do treino\n",
    "    qs = np.quantile(tr, np.linspace(0, 1, 11))\n",
    "    bins = np.unique(qs)\n",
    "    if len(bins) < 3:\n",
    "        psi = 0.0\n",
    "        ks  = 0.0\n",
    "    else:\n",
    "        psi = psi_from_bins(tr, te, bins)\n",
    "        ks  = float(ks_2samp(tr, te, alternative=\"two-sided\").statistic)\n",
    "    rows.append({\"feature\": feat_names[j], \"psi_train_test\": psi, \"ks_train_test\": ks})\n",
    "\n",
    "df_drift = pd.DataFrame(rows).sort_values([\"psi_train_test\",\"ks_train_test\"], ascending=False)\n",
    "df_drift.to_csv(os.path.join(FREEZE_DIR, \"drift_psi_ks_train_vs_test.csv\"), index=False)\n",
    "\n",
    "print(\"OK: Drift salvo em drift_psi_ks_train_vs_test.csv (ordenado por maior PSI/KS).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d2e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seleção de modelo: multi | origem: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\rf_gold_20250818_0826.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\wilso\\AppData\\Local\\Temp\\ipykernel_38792\\636128430.py:115: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tbl = dfm.groupby([\"split\",\"cluster\"], dropna=False).apply(agg_metrics).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: Métricas por cluster salvas em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\metrics_by_cluster_kmeans.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wm",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0b4dd97a-5a2c-4de1-9653-0faa311c23f5",
       "rows": [
        [
         "0",
         "test",
         "1",
         "2001.0",
         "0.7555313839613604",
         "1.0838959098182045e-07",
         "0.6977987427390622",
         "58664.260830891195"
        ],
        [
         "1",
         "train",
         "0",
         "4986.0",
         "0.8681134103520005",
         "4.3406366957552795e-09",
         "-1.231608326099591",
         "50.18491356797296"
        ],
        [
         "2",
         "train",
         "1",
         "2017.0",
         "0.9889410805144252",
         "6.464655571239608e-09",
         "0.9956305907610928",
         "1649.876051204043"
        ],
        [
         "3",
         "val",
         "1",
         "1001.0",
         "0.9307405554581266",
         "5.3710211866290645e-08",
         "0.9251247772044555",
         "26756.00187413825"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>cluster</th>\n",
       "      <th>n</th>\n",
       "      <th>R2_wr</th>\n",
       "      <th>MAE_wr</th>\n",
       "      <th>R2_wm</th>\n",
       "      <th>MAE_wm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.755531</td>\n",
       "      <td>1.083896e-07</td>\n",
       "      <td>0.697799</td>\n",
       "      <td>58664.260831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>4986.0</td>\n",
       "      <td>0.868113</td>\n",
       "      <td>4.340637e-09</td>\n",
       "      <td>-1.231608</td>\n",
       "      <td>50.184914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.988941</td>\n",
       "      <td>6.464656e-09</td>\n",
       "      <td>0.995631</td>\n",
       "      <td>1649.876051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.930741</td>\n",
       "      <td>5.371021e-08</td>\n",
       "      <td>0.925125</td>\n",
       "      <td>26756.001874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  cluster       n     R2_wr        MAE_wr     R2_wm        MAE_wm\n",
       "0   test        1  2001.0  0.755531  1.083896e-07  0.697799  58664.260831\n",
       "1  train        0  4986.0  0.868113  4.340637e-09 -1.231608     50.184914\n",
       "2  train        1  2017.0  0.988941  6.464656e-09  0.995631   1649.876051\n",
       "3    val        1  1001.0  0.930741  5.371021e-08  0.925125  26756.001874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ETAPA: ERRO POR CLUSTER (KMEANS) — ROBUSTO A MODELOS 1-ALVO OU MULTI-ALVO\n",
    "import os, joblib, numpy as np, pandas as pd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "YCOLS = [\"wr_kg_m2_h\",\"wm_kg_m2_h\"]\n",
    "MODELS_DIR = os.path.join(FREEZE_DIR, \"models\")\n",
    "\n",
    "def pick_model_pack(models_dir):\n",
    "    packs = []\n",
    "    for f in os.listdir(models_dir):\n",
    "        if not f.endswith(\".joblib\"):\n",
    "            continue\n",
    "        p = os.path.join(models_dir, f)\n",
    "        try:\n",
    "            pack = joblib.load(p)\n",
    "            packs.append((p, pack, os.path.getmtime(p)))\n",
    "        except Exception:\n",
    "            continue\n",
    "    # 1) Preferir multi-alvo (tem 'y_names' com os dois alvos)\n",
    "    multi = [x for x in packs if isinstance(x[1].get(\"y_names\", None), list) and set(x[1][\"y_names\"]) == set(YCOLS)]\n",
    "    if multi:\n",
    "        multi.sort(key=lambda x: x[2], reverse=True)  # mais recente\n",
    "        return {\"type\":\"multi\", \"path\": multi[0][0], \"pack\": multi[0][1]}\n",
    "    # 2) Caso contrário, procurar os dois single-target\n",
    "    wrs = [x for x in packs if x[1].get(\"target\") == YCOLS[0]]\n",
    "    wms = [x for x in packs if x[1].get(\"target\") == YCOLS[1]]\n",
    "    if wrs and wms:\n",
    "        wrs.sort(key=lambda x: x[2], reverse=True)\n",
    "        wms.sort(key=lambda x: x[2], reverse=True)\n",
    "        return {\"type\":\"dual\", \"wr\": wrs[0], \"wm\": wms[0]}\n",
    "    # 3) Último recurso: qualquer single\n",
    "    if packs:\n",
    "        packs.sort(key=lambda x: x[2], reverse=True)\n",
    "        return {\"type\":\"single\", \"one\": packs[0]}\n",
    "    raise FileNotFoundError(\"Nenhum modelo .joblib válido encontrado em: \" + models_dir)\n",
    "\n",
    "sel = pick_model_pack(MODELS_DIR)\n",
    "src = sel[\"path\"] if sel[\"type\"]==\"multi\" else (sel[\"wr\"][0] if sel[\"type\"]==\"dual\" else sel[\"one\"][0])\n",
    "print(\"Seleção de modelo:\", sel[\"type\"], \"| origem:\", src)\n",
    "\n",
    "# ---------- Carrega dados (para y_true e X) ----------\n",
    "dfr = pd.read_csv(os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\"), header=[0,1], engine=\"python\")\n",
    "df  = dfr.copy(); df.columns = [c for (c,_) in dfr.columns]\n",
    "y_all = df[YCOLS].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "X_all = df.drop(columns=YCOLS).select_dtypes(include=[np.number]).values\n",
    "\n",
    "# ---------- Predições (multi, dual, single) ----------\n",
    "if sel[\"type\"] == \"multi\":\n",
    "    pack = sel[\"pack\"]\n",
    "    imp, sc, model = pack[\"imputer\"], pack[\"scaler\"], pack[\"model\"]\n",
    "    X_all_p = sc.transform(imp.transform(X_all))\n",
    "    y_pred = model.predict(X_all_p)\n",
    "    # garantir 2D\n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred = y_pred.reshape(-1,1)\n",
    "        # completa com NaN na segunda coluna\n",
    "        y_pred = np.hstack([y_pred, np.full((y_pred.shape[0],1), np.nan)])\n",
    "elif sel[\"type\"] == \"dual\":\n",
    "    pack_wr = sel[\"wr\"][1]; pack_wm = sel[\"wm\"][1]\n",
    "    # assumindo mesmo imputer/scaler (foram treinados no GOLD)\n",
    "    imp, sc = pack_wr[\"imputer\"], pack_wr[\"scaler\"]\n",
    "    X_all_p = sc.transform(imp.transform(X_all))\n",
    "    pred_wr = pack_wr[\"model\"].predict(X_all_p).reshape(-1,1)\n",
    "    pred_wm = pack_wm[\"model\"].predict(X_all_p).reshape(-1,1)\n",
    "    y_pred = np.hstack([pred_wr, pred_wm])\n",
    "else:  # single fallback\n",
    "    pack_one = sel[\"one\"][1]\n",
    "    imp, sc, model = pack_one[\"imputer\"], pack_one[\"scaler\"], pack_one[\"model\"]\n",
    "    X_all_p = sc.transform(imp.transform(X_all))\n",
    "    pred_one = model.predict(X_all_p).reshape(-1,1)\n",
    "    y_pred = np.full((len(df), 2), np.nan)\n",
    "    tgt = pack_one.get(\"target\")\n",
    "    if tgt == YCOLS[0]:\n",
    "        y_pred[:,0] = pred_one.ravel()\n",
    "    elif tgt == YCOLS[1]:\n",
    "        y_pred[:,1] = pred_one.ravel()\n",
    "    else:\n",
    "        # sem meta declarada: coloca na 1ª coluna\n",
    "        y_pred[:,0] = pred_one.ravel()\n",
    "\n",
    "# ---------- Labels de cluster/split ----------\n",
    "labels = pd.read_csv(os.path.join(FREEZE_DIR, \"kmeans_labels.csv\"))\n",
    "clusters = labels[\"cluster\"].values\n",
    "split    = labels[\"split\"].values\n",
    "\n",
    "# ---------- Agregação de métricas por split e cluster ----------\n",
    "dfm = pd.DataFrame({\n",
    "    \"split\": split,\n",
    "    \"cluster\": clusters,\n",
    "    \"wr_true\": y_all[:,0],\n",
    "    \"wm_true\": y_all[:,1],\n",
    "    \"wr_pred\": y_pred[:,0],\n",
    "    \"wm_pred\": y_pred[:,1],\n",
    "})\n",
    "\n",
    "def agg_metrics(g):\n",
    "    out = {\"n\": int(len(g))}\n",
    "    # wr\n",
    "    mwr = g[[\"wr_true\",\"wr_pred\"]].dropna()\n",
    "    if len(mwr) >= 5 and np.var(mwr[\"wr_true\"]) > 0:\n",
    "        out[\"R2_wr\"]  = float(r2_score(mwr[\"wr_true\"], mwr[\"wr_pred\"]))\n",
    "        out[\"MAE_wr\"] = float(mean_absolute_error(mwr[\"wr_true\"], mwr[\"wr_pred\"]))\n",
    "    else:\n",
    "        out[\"R2_wr\"] = np.nan; out[\"MAE_wr\"] = np.nan\n",
    "    # wm\n",
    "    mwm = g[[\"wm_true\",\"wm_pred\"]].dropna()\n",
    "    if len(mwm) >= 5 and np.var(mwm[\"wm_true\"]) > 0:\n",
    "        out[\"R2_wm\"]  = float(r2_score(mwm[\"wm_true\"], mwm[\"wm_pred\"]))\n",
    "        out[\"MAE_wm\"] = float(mean_absolute_error(mwm[\"wm_true\"], mwm[\"wm_pred\"]))\n",
    "    else:\n",
    "        out[\"R2_wm\"] = np.nan; out[\"MAE_wm\"] = np.nan\n",
    "    return pd.Series(out)\n",
    "\n",
    "tbl = dfm.groupby([\"split\",\"cluster\"], dropna=False).apply(agg_metrics).reset_index()\n",
    "out_path = os.path.join(FREEZE_DIR, \"metrics_by_cluster_kmeans.csv\")\n",
    "tbl.to_csv(out_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"OK: Métricas por cluster salvas em:\", out_path)\n",
    "display(tbl.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96246e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos carregados:\n",
      " - drift: OK\n",
      " - kgrid: OK\n",
      " - klabels: OK\n",
      " - kcent: OK\n",
      " - kerr: OK\n",
      " - pca_var: OK\n",
      "\n",
      "TOP-15 DRIFT (PSI/KS):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "psi_train_test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ks_train_test",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a5579a94-aa3c-40be-8fd8-faf7fe287a72",
       "rows": [
        [
         "0",
         "hi_temperture_reheol_pres_mpa",
         "12.454367011550254",
         "0.9757963371591372"
        ],
        [
         "1",
         "ar_sec_vent_a_fq_speed_feedback",
         "11.81616234609979",
         "0.9797944095209286"
        ],
        [
         "2",
         "pressao_ar_sec_vent_a_saida",
         "10.560513500649568",
         "0.4997858060831072"
        ],
        [
         "3",
         "pressao_ar_flu_ap_vent_c_saida_head",
         "10.173863029760284",
         "0.7119805797515351"
        ],
        [
         "4",
         "pressao_condensado_bomba_a_saida",
         "9.773944354183415",
         "0.783456551033351"
        ],
        [
         "5",
         "temp_ar_flu_ap_vent_saida_head_pipe",
         "9.569259144250012",
         "0.722547551013869"
        ],
        [
         "6",
         "unit_actual",
         "9.464231834865313",
         "0.7324013275384298"
        ],
        [
         "7",
         "temp_3_lph_saida_wtr",
         "9.36300603056988",
         "0.7280502972846006"
        ],
        [
         "8",
         "temp_cnd_bomba_saida_header",
         "9.338918615518187",
         "0.7244808268434682"
        ],
        [
         "9",
         "t_bfbp_b_entrada_temp",
         "9.240633327832995",
         "0.7120565805916119"
        ],
        [
         "10",
         "temp_hot_pri_air_in_preaq_ar_saida",
         "9.22765097614299",
         "0.7129801513637013"
        ],
        [
         "11",
         "corr_primary_air_vent_motor_b_a",
         "9.224597418392491",
         "0.7122661716407254"
        ],
        [
         "12",
         "so2_concentration_raw_flue_gas_mg_m3",
         "9.194121300962756",
         "0.7724546979687366"
        ],
        [
         "13",
         "pressao_gas_in_ltr_lado_b_entrada",
         "9.186366115436511",
         "0.7119805797515351"
        ],
        [
         "14",
         "vent_tiragem_vent_a_saida_pressao",
         "9.170000210975475",
         "0.7128373554191061"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>psi_train_test</th>\n",
       "      <th>ks_train_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi_temperture_reheol_pres_mpa</td>\n",
       "      <td>12.454367</td>\n",
       "      <td>0.975796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ar_sec_vent_a_fq_speed_feedback</td>\n",
       "      <td>11.816162</td>\n",
       "      <td>0.979794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pressao_ar_sec_vent_a_saida</td>\n",
       "      <td>10.560514</td>\n",
       "      <td>0.499786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pressao_ar_flu_ap_vent_c_saida_head</td>\n",
       "      <td>10.173863</td>\n",
       "      <td>0.711981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pressao_condensado_bomba_a_saida</td>\n",
       "      <td>9.773944</td>\n",
       "      <td>0.783457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>temp_ar_flu_ap_vent_saida_head_pipe</td>\n",
       "      <td>9.569259</td>\n",
       "      <td>0.722548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unit_actual</td>\n",
       "      <td>9.464232</td>\n",
       "      <td>0.732401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>temp_3_lph_saida_wtr</td>\n",
       "      <td>9.363006</td>\n",
       "      <td>0.728050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>temp_cnd_bomba_saida_header</td>\n",
       "      <td>9.338919</td>\n",
       "      <td>0.724481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t_bfbp_b_entrada_temp</td>\n",
       "      <td>9.240633</td>\n",
       "      <td>0.712057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>temp_hot_pri_air_in_preaq_ar_saida</td>\n",
       "      <td>9.227651</td>\n",
       "      <td>0.712980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>corr_primary_air_vent_motor_b_a</td>\n",
       "      <td>9.224597</td>\n",
       "      <td>0.712266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>so2_concentration_raw_flue_gas_mg_m3</td>\n",
       "      <td>9.194121</td>\n",
       "      <td>0.772455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pressao_gas_in_ltr_lado_b_entrada</td>\n",
       "      <td>9.186366</td>\n",
       "      <td>0.711981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vent_tiragem_vent_a_saida_pressao</td>\n",
       "      <td>9.170000</td>\n",
       "      <td>0.712837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 feature  psi_train_test  ks_train_test\n",
       "0          hi_temperture_reheol_pres_mpa       12.454367       0.975796\n",
       "1        ar_sec_vent_a_fq_speed_feedback       11.816162       0.979794\n",
       "2            pressao_ar_sec_vent_a_saida       10.560514       0.499786\n",
       "3    pressao_ar_flu_ap_vent_c_saida_head       10.173863       0.711981\n",
       "4       pressao_condensado_bomba_a_saida        9.773944       0.783457\n",
       "5    temp_ar_flu_ap_vent_saida_head_pipe        9.569259       0.722548\n",
       "6                            unit_actual        9.464232       0.732401\n",
       "7                   temp_3_lph_saida_wtr        9.363006       0.728050\n",
       "8            temp_cnd_bomba_saida_header        9.338919       0.724481\n",
       "9                  t_bfbp_b_entrada_temp        9.240633       0.712057\n",
       "10    temp_hot_pri_air_in_preaq_ar_saida        9.227651       0.712980\n",
       "11       corr_primary_air_vent_motor_b_a        9.224597       0.712266\n",
       "12  so2_concentration_raw_flue_gas_mg_m3        9.194121       0.772455\n",
       "13     pressao_gas_in_ltr_lado_b_entrada        9.186366       0.711981\n",
       "14     vent_tiragem_vent_a_saida_pressao        9.170000       0.712837"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KMeans (melhor k pelo silhouette no treino):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "k",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "silhouette_train",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "27a514aa-1315-4274-b3ac-069f8a54a1bf",
       "rows": [
        [
         "0",
         "2",
         "0.5747290720616345"
        ],
        [
         "1",
         "3",
         "0.2783630123729031"
        ],
        [
         "2",
         "7",
         "0.2474774281202918"
        ],
        [
         "3",
         "10",
         "0.223667973118908"
        ],
        [
         "4",
         "5",
         "0.2102890597961841"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>silhouette_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.574729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.278363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.247477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.223668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.210289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  silhouette_train\n",
       "0   2          0.574729\n",
       "1   3          0.278363\n",
       "2   7          0.247477\n",
       "3  10          0.223668\n",
       "4   5          0.210289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MÉTRICAS POR CLUSTER (R2/MAE):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cluster",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wm",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "63f4e467-5554-48dc-8eee-4481cb5c393d",
       "rows": [
        [
         "0",
         "test",
         "1",
         "2001.0",
         "0.7555313839613604",
         "1.0838959098182045e-07",
         "0.6977987427390622",
         "58664.2608308912"
        ],
        [
         "1",
         "train",
         "0",
         "4986.0",
         "0.8681134103520005",
         "4.3406366957552795e-09",
         "-1.231608326099591",
         "50.18491356797296"
        ],
        [
         "2",
         "train",
         "1",
         "2017.0",
         "0.9889410805144252",
         "6.464655571239608e-09",
         "0.9956305907610928",
         "1649.876051204043"
        ],
        [
         "3",
         "val",
         "1",
         "1001.0",
         "0.9307405554581266",
         "5.371021186629065e-08",
         "0.9251247772044556",
         "26756.00187413825"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>cluster</th>\n",
       "      <th>n</th>\n",
       "      <th>R2_wr</th>\n",
       "      <th>MAE_wr</th>\n",
       "      <th>R2_wm</th>\n",
       "      <th>MAE_wm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.755531</td>\n",
       "      <td>1.083896e-07</td>\n",
       "      <td>0.697799</td>\n",
       "      <td>58664.260831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>4986.0</td>\n",
       "      <td>0.868113</td>\n",
       "      <td>4.340637e-09</td>\n",
       "      <td>-1.231608</td>\n",
       "      <td>50.184914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0.988941</td>\n",
       "      <td>6.464656e-09</td>\n",
       "      <td>0.995631</td>\n",
       "      <td>1649.876051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.930741</td>\n",
       "      <td>5.371021e-08</td>\n",
       "      <td>0.925125</td>\n",
       "      <td>26756.001874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  cluster       n     R2_wr        MAE_wr     R2_wm        MAE_wm\n",
       "0   test        1  2001.0  0.755531  1.083896e-07  0.697799  58664.260831\n",
       "1  train        0  4986.0  0.868113  4.340637e-09 -1.231608     50.184914\n",
       "2  train        1  2017.0  0.988941  6.464656e-09  0.995631   1649.876051\n",
       "3    val        1  1001.0  0.930741  5.371021e-08  0.925125  26756.001874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ETAPA: SUMÁRIO DOS ACHADOS (DRIFT + CLUSTERS + ERROS)\n",
    "import os, pandas as pd\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "\n",
    "paths = {\n",
    "    \"drift\":  os.path.join(FREEZE_DIR, \"drift_psi_ks_train_vs_test.csv\"),\n",
    "    \"kgrid\":  os.path.join(FREEZE_DIR, \"kmeans_silhouette_train.csv\"),\n",
    "    \"klabels\":os.path.join(FREEZE_DIR, \"kmeans_labels.csv\"),\n",
    "    \"kcent\":  os.path.join(FREEZE_DIR, \"kmeans_centroids_pcspace.csv\"),\n",
    "    \"kerr\":   os.path.join(FREEZE_DIR, \"metrics_by_cluster_kmeans.csv\"),\n",
    "    \"pca_var\":os.path.join(FREEZE_DIR, \"pca_explained_variance.csv\"),\n",
    "}\n",
    "\n",
    "dfs = {k:(pd.read_csv(v) if os.path.exists(v) else None) for k,v in paths.items()}\n",
    "print(\"Arquivos carregados:\")\n",
    "for k,v in paths.items():\n",
    "    print(f\" - {k}: {'OK' if os.path.exists(v) else 'AUSENTE'}\")\n",
    "\n",
    "# Mostra top-15 features com maior drift\n",
    "if dfs[\"drift\"] is not None:\n",
    "    print(\"\\nTOP-15 DRIFT (PSI/KS):\")\n",
    "    display(dfs[\"drift\"].head(15))\n",
    "\n",
    "# Melhor k pelo silhouette\n",
    "if dfs[\"kgrid\"] is not None:\n",
    "    print(\"\\nKMeans (melhor k pelo silhouette no treino):\")\n",
    "    display(dfs[\"kgrid\"].sort_values('silhouette_train', ascending=False).head(5))\n",
    "\n",
    "# Métricas por cluster\n",
    "if dfs[\"kerr\"] is not None:\n",
    "    print(\"\\nMÉTRICAS POR CLUSTER (R2/MAE):\")\n",
    "    display(dfs[\"kerr\"].head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df04c920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILD concluído.\n",
      "Base: (10005, 144) | Regime+dist: 4 | Lags: 50\n",
      "Top-PSI (lags): ['hi_temperture_reheol_pres_mpa', 'ar_sec_vent_a_fq_speed_feedback', 'pressao_ar_sec_vent_a_saida', 'pressao_ar_flu_ap_vent_c_saida_head', 'pressao_condensado_bomba_a_saida', 'temp_ar_flu_ap_vent_saida_head_pipe', 'unit_actual', 'temp_3_lph_saida_wtr', 'temp_cnd_bomba_saida_header', 't_bfbp_b_entrada_temp']\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# BUILD: Features com regime (KMeans) + distâncias + lags top-PSI\n",
    "# ==========================================\n",
    "import os, json, joblib, numpy as np, pandas as pd\n",
    "from scipy.stats import iqr\n",
    "\n",
    "# ---- paths\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "PATH_FEATS_GOLD = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\")\n",
    "PATH_SPLITS     = os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\")\n",
    "PATH_IMPUTER    = os.path.join(FREEZE_DIR, \"imputer_gold_median.joblib\")  # só para referência; novos imputer/scaler serão criados por experimento\n",
    "PATH_SCALER     = os.path.join(FREEZE_DIR, \"scaler_gold_standard.joblib\")\n",
    "PATH_DRIFT      = os.path.join(FREEZE_DIR, \"drift_psi_ks_train_vs_test.csv\")\n",
    "PATH_KLAB       = os.path.join(FREEZE_DIR, \"kmeans_labels.csv\")\n",
    "PATH_KCENT      = os.path.join(FREEZE_DIR, \"kmeans_centroids_pcspace.csv\")\n",
    "PATH_PCSCORES   = os.path.join(FREEZE_DIR, \"pca_scores.csv\")\n",
    "\n",
    "# ---- carregar base GOLD e preparar X/Y\n",
    "dfr = pd.read_csv(PATH_FEATS_GOLD, header=[0,1], engine=\"python\")\n",
    "df  = dfr.copy()\n",
    "df.columns = [c for (c,_) in dfr.columns]  # usar cabeçalho de nomes\n",
    "timestamp = pd.to_datetime(df.iloc[:,0], errors=\"coerce\")\n",
    "YCOLS = [\"wr_kg_m2_h\", \"wm_kg_m2_h\"]\n",
    "\n",
    "X_base = df.drop(columns=YCOLS).select_dtypes(include=[np.number]).copy()\n",
    "y_all  = df[YCOLS].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "\n",
    "# ---- splits\n",
    "splits = joblib.load(PATH_SPLITS)\n",
    "idx_tr, idx_va, idx_te = splits[\"train\"], splits[\"val\"], splits[\"test\"]\n",
    "\n",
    "# ---- regime KMeans (k=best) e distâncias aos centróides (PC-space)\n",
    "klabels   = pd.read_csv(PATH_KLAB)            # columns: timestamp, split, kmeans_k, cluster\n",
    "kcent     = pd.read_csv(PATH_KCENT)           # columns: cluster, PC1..PCm\n",
    "scores    = pd.read_csv(PATH_PCSCORES)        # columns: timestamp, split, PC1..PCn\n",
    "pc_cols   = [c for c in kcent.columns if c.startswith(\"PC\")]\n",
    "assert len(pc_cols) > 0, \"Centróides PCA sem colunas PC*.\"\n",
    "assert len(scores) == len(df), \"pca_scores.csv não está alinhado ao dataframe.\"\n",
    "\n",
    "# rótulos e one-hot\n",
    "clusters = klabels[\"cluster\"].astype(int).values\n",
    "X_regime = pd.get_dummies(clusters, prefix=\"kmeans_c\", dtype=float)\n",
    "# garantir colunas ordenadas e contínuas\n",
    "for c in sorted(kcent[\"cluster\"].unique()):\n",
    "    col = f\"kmeans_c_{int(c)}\"\n",
    "    if col not in X_regime.columns:\n",
    "        X_regime[col] = 0.0\n",
    "X_regime = X_regime[sorted(X_regime.columns)]\n",
    "\n",
    "# distâncias por centróide (em PC-space)\n",
    "pc_matrix = scores[pc_cols].values\n",
    "centroids = {int(row[\"cluster\"]): row[pc_cols].values for _, row in kcent.iterrows()}\n",
    "dist_cols = []\n",
    "dist_data = []\n",
    "for cl, ctr in sorted(centroids.items()):\n",
    "    d = np.linalg.norm(pc_matrix - ctr, axis=1)\n",
    "    dist_data.append(d)\n",
    "    dist_cols.append(f\"kmeans_dist_c{cl}\")\n",
    "X_dist = pd.DataFrame(np.vstack(dist_data).T, columns=dist_cols)\n",
    "\n",
    "# ---- lags nas top-PSI features (apenas onde há drift)\n",
    "drift = pd.read_csv(PATH_DRIFT).sort_values([\"psi_train_test\",\"ks_train_test\"], ascending=False)\n",
    "top_features = [f for f in drift[\"feature\"].tolist() if f in X_base.columns][:10]  # top-10 existentes\n",
    "lag_hours = [1, 3, 6, 12, 24]  # assume amostragem horária; shift por linha preserva ordem temporal\n",
    "\n",
    "X_lags = pd.DataFrame(index=X_base.index)\n",
    "for f in top_features:\n",
    "    for h in lag_hours:\n",
    "        X_lags[f\"lag{h}h__{f}\"] = X_base[f].shift(h)\n",
    "\n",
    "# ---- consolidar design\n",
    "X_aug = pd.concat([X_base, X_regime, X_dist, X_lags], axis=1)\n",
    "\n",
    "# ---- meta-informação para os próximos passos\n",
    "meta = {\n",
    "    \"n_rows\": int(len(df)),\n",
    "    \"n_features_base\": int(X_base.shape[1]),\n",
    "    \"n_features_regime\": int(X_regime.shape[1] + X_dist.shape[1]),\n",
    "    \"n_features_lags\": int(X_lags.shape[1]),\n",
    "    \"top_features_for_lags\": top_features,\n",
    "    \"lag_hours\": lag_hours,\n",
    "    \"kmeans_clusters\": sorted([int(x) for x in kcent[\"cluster\"].unique()]),\n",
    "}\n",
    "with open(os.path.join(FREEZE_DIR, \"exp_unsup_guided_meta.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# ---- salvar design para auditoria (opcional, pode ser grande)\n",
    "X_aug.to_csv(os.path.join(FREEZE_DIR, \"X_augmented_preview.csv\"), index=False)  # preview (pode comentar se ficar pesado)\n",
    "\n",
    "print(\"BUILD concluído.\")\n",
    "print(\"Base:\", X_base.shape, \"| Regime+dist:\", (X_regime.shape[1] + X_dist.shape[1]), \"| Lags:\", X_lags.shape[1])\n",
    "print(\"Top-PSI (lags):\", top_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34d2f753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Rodando E0_baseline_RF | cols=144 | reweight=False | hgbr=False\n",
      "==> Rodando E1_regime_RF | cols=148 | reweight=False | hgbr=False\n",
      "==> Rodando E2_regime_reweight_RF | cols=148 | reweight=True | hgbr=False\n",
      "==> Rodando E3_regime_lags_reweight_RF | cols=198 | reweight=True | hgbr=False\n",
      "==> Rodando E4_regime_lags_reweight_HGBR | cols=198 | reweight=True | hgbr=True\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'loss' parameter of HistGradientBoostingRegressor must be a str among {'quantile', 'poisson', 'squared_error', 'absolute_error', 'gamma'} or an instance of 'sklearn._loss.loss.BaseLoss'. Got 'huber' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidParameterError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 135\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, Xmat, rewt, use_hgbr \u001b[38;5;129;01min\u001b[39;00m experiments:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m==> Rodando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | cols=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mXmat.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | reweight=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrewt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | hgbr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muse_hgbr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     dfm, mpath = \u001b[43mfit_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_reweight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrewt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_hgbr\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_hgbr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     all_rows.append(dfm); models_paths.append((name, mpath))\n\u001b[32m    138\u001b[39m res = pd.concat(all_rows, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mfit_eval\u001b[39m\u001b[34m(nome_exp, Xall, yall, use_reweight, use_hgbr)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# fit\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[43mest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     87\u001b[39m     est.fit(X_tr_p, y_tr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\multioutput.py:278\u001b[39m, in \u001b[36m_MultiOutputEstimator.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    276\u001b[39m         routed_params.estimator.fit[\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m] = sample_weight\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mn_features_in_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_features_in_ = \u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m].n_features_in_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\multioutput.py:65\u001b[39m, in \u001b[36m_fit_estimator\u001b[39m\u001b[34m(estimator, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m     63\u001b[39m estimator = clone(estimator)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     67\u001b[39m     estimator.fit(X, y, **fit_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\base.py:1358\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1353\u001b[39m partial_fit_and_fitted = (\n\u001b[32m   1354\u001b[39m     fit_method.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33mpartial_fit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[32m   1355\u001b[39m )\n\u001b[32m   1357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[32m-> \u001b[39m\u001b[32m1358\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m   1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\base.py:471\u001b[39m, in \u001b[36mBaseEstimator._validate_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    464\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[32m    465\u001b[39m \n\u001b[32m    466\u001b[39m \u001b[33;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m \u001b[33;03m    accepted constraints.\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[39m, in \u001b[36mvalidate_parameter_constraints\u001b[39m\u001b[34m(parameter_constraints, params, caller_name)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     93\u001b[39m     constraints_str = (\n\u001b[32m     94\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:-\u001b[32m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[32m     99\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m )\n",
      "\u001b[31mInvalidParameterError\u001b[39m: The 'loss' parameter of HistGradientBoostingRegressor must be a str among {'quantile', 'poisson', 'squared_error', 'absolute_error', 'gamma'} or an instance of 'sklearn._loss.loss.BaseLoss'. Got 'huber' instead."
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EXPERIMENTOS: Baseline e variações (regime, reweight, lags, HGBR huber)\n",
    "# ============================================================\n",
    "import os, json, joblib, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import iqr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "# ---- paths\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "PATH_FEATS_GOLD = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\")\n",
    "PATH_SPLITS     = os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\")\n",
    "PATH_KLAB       = os.path.join(FREEZE_DIR, \"kmeans_labels.csv\")\n",
    "\n",
    "# ---- dados\n",
    "dfr = pd.read_csv(PATH_FEATS_GOLD, header=[0,1], engine=\"python\")\n",
    "df  = dfr.copy(); df.columns = [c for (c,_) in dfr.columns]\n",
    "timestamp = pd.to_datetime(df.iloc[:,0], errors=\"coerce\")\n",
    "YCOLS = [\"wr_kg_m2_h\", \"wm_kg_m2_h\"]\n",
    "X_base = df.drop(columns=YCOLS).select_dtypes(include=[np.number]).copy()\n",
    "y_all  = df[YCOLS].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "\n",
    "splits = joblib.load(PATH_SPLITS)\n",
    "idx_tr, idx_va, idx_te = splits[\"train\"], splits[\"val\"], splits[\"test\"]\n",
    "\n",
    "# ---- features construídas\n",
    "X_aug = pd.read_csv(os.path.join(FREEZE_DIR, \"X_augmented_preview.csv\"))\n",
    "klabels = pd.read_csv(PATH_KLAB)\n",
    "clusters = klabels[\"cluster\"].astype(int).values\n",
    "\n",
    "# ---- utilidades\n",
    "def mae_iqr(y_true, y_pred):\n",
    "    e = np.abs(y_true - y_pred); den = iqr(y_true) or 1.0\n",
    "    return float(np.mean(e)/den)\n",
    "\n",
    "def resumo(nome_exp, split_name, idx, y, yhat, tstamp):\n",
    "    r = {\"exp\": nome_exp, \"split\": split_name, \"linhas\": int(len(idx))}\n",
    "    r[\"inicio\"] = str(pd.to_datetime(tstamp.iloc[idx].min()))\n",
    "    r[\"fim\"]    = str(pd.to_datetime(tstamp.iloc[idx].max()))\n",
    "    for j, alvo in enumerate(YCOLS):\n",
    "        yt, yp = y[:,j], yhat[:,j]\n",
    "        r[f\"R2_{alvo}\"]      = float(r2_score(yt, yp)) if np.var(yt) > 0 else np.nan\n",
    "        r[f\"RMSE_{alvo}\"]    = float(mean_squared_error(yt, yp) ** 0.5)\n",
    "        r[f\"MAE_{alvo}\"]     = float(mean_absolute_error(yt, yp))\n",
    "        r[f\"MAE_IQR_{alvo}\"] = float(mae_iqr(yt, yp))\n",
    "    return r\n",
    "\n",
    "def fit_eval(nome_exp, Xall, yall, use_reweight=False, use_hgbr=False):\n",
    "    # split\n",
    "    X_tr = Xall.iloc[idx_tr]; X_va = Xall.iloc[idx_va]; X_te = Xall.iloc[idx_te]\n",
    "    y_tr = yall[idx_tr];      y_va = yall[idx_va];      y_te = yall[idx_te]\n",
    "\n",
    "    # imputer + scaler (treina no treino)\n",
    "    imp = SimpleImputer(strategy=\"median\")\n",
    "    sc  = StandardScaler()\n",
    "    X_tr_p = sc.fit_transform(imp.fit_transform(X_tr))\n",
    "    X_va_p = sc.transform(imp.transform(X_va))\n",
    "    X_te_p = sc.transform(imp.transform(X_te))\n",
    "\n",
    "    # estimator\n",
    "    if use_hgbr:\n",
    "        base = HistGradientBoostingRegressor(loss=\"huber\", random_state=42)\n",
    "    else:\n",
    "        base = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "    est = MultiOutputRegressor(base)\n",
    "\n",
    "    # sample weights (reponderação por cluster para TREINO)\n",
    "    sw = None\n",
    "    if use_reweight:\n",
    "        c_tr = clusters[idx_tr]; c_te = clusters[idx_te]\n",
    "        # proporções alvo = teste\n",
    "        uniq = np.unique(np.concatenate([c_tr, c_te]))\n",
    "        p_tr = {c: max(1e-6, (c_tr==c).mean()) for c in uniq}\n",
    "        p_te = {c:        (c_te==c).mean()     for c in uniq}\n",
    "        wmap = {c: p_te[c]/p_tr[c] for c in uniq}\n",
    "        sw = np.array([wmap.get(c, 1.0) for c in c_tr], dtype=float)\n",
    "        sw = sw * (len(sw)/sw.sum())  # normalizar para média ~1\n",
    "\n",
    "    # fit\n",
    "    if sw is not None:\n",
    "        est.fit(X_tr_p, y_tr, sample_weight=sw)\n",
    "    else:\n",
    "        est.fit(X_tr_p, y_tr)\n",
    "\n",
    "    # preds\n",
    "    yhat_tr = est.predict(X_tr_p)\n",
    "    yhat_va = est.predict(X_va_p)\n",
    "    yhat_te = est.predict(X_te_p)\n",
    "\n",
    "    # métricas\n",
    "    rows = []\n",
    "    rows.append(resumo(nome_exp, \"treino\",    idx_tr, y_tr, yhat_tr, timestamp))\n",
    "    rows.append(resumo(nome_exp, \"validacao\", idx_va, y_va, yhat_va, timestamp))\n",
    "    rows.append(resumo(nome_exp, \"teste\",     idx_te, y_te, yhat_te, timestamp))\n",
    "\n",
    "    # persistência do modelo\n",
    "    tag = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    model_path = os.path.join(FREEZE_DIR, \"models\", f\"{nome_exp}_{tag}.joblib\")\n",
    "    joblib.dump({\"model\": est, \"imputer\": imp, \"scaler\": sc, \"y_names\": YCOLS, \"features\": list(Xall.columns)}, model_path)\n",
    "\n",
    "    return pd.DataFrame(rows), model_path\n",
    "\n",
    "# ---- definir experimentos\n",
    "# E0: Baseline (somente X_base)\n",
    "# E1: X_aug sem lags (regime + distâncias)\n",
    "# E2: E1 com reweight\n",
    "# E3: X_aug completo (regime + distâncias + lags) + reweight\n",
    "# E4: Igual ao E3, mas com HGBR (huber) no lugar de RF\n",
    "lag_cols   = [c for c in X_aug.columns if c.startswith(\"lag\")]\n",
    "reg_cols   = [c for c in X_aug.columns if c.startswith(\"kmeans_c_\") or c.startswith(\"kmeans_dist_\")]\n",
    "\n",
    "X_E0 = X_base.copy()\n",
    "X_E1 = pd.concat([X_base, X_aug[reg_cols]], axis=1)\n",
    "X_E2 = X_E1.copy()\n",
    "X_E3 = pd.concat([X_base, X_aug[reg_cols + lag_cols]], axis=1)\n",
    "X_E4 = X_E3.copy()\n",
    "\n",
    "experiments = [\n",
    "    (\"E0_baseline_RF\",               X_E0, False, False),\n",
    "    (\"E1_regime_RF\",                 X_E1, False, False),\n",
    "    (\"E2_regime_reweight_RF\",        X_E2, True,  False),\n",
    "    (\"E3_regime_lags_reweight_RF\",   X_E3, True,  False),\n",
    "    (\"E4_regime_lags_reweight_HGBR\", X_E4, True,  True ),\n",
    "]\n",
    "\n",
    "# ---- rodar\n",
    "all_rows = []\n",
    "models_paths = []\n",
    "for name, Xmat, rewt, use_hgbr in experiments:\n",
    "    print(f\"==> Rodando {name} | cols={Xmat.shape[1]} | reweight={rewt} | hgbr={use_hgbr}\")\n",
    "    dfm, mpath = fit_eval(name, Xmat, y_all, use_reweight=rewt, use_hgbr=use_hgbr)\n",
    "    all_rows.append(dfm); models_paths.append((name, mpath))\n",
    "\n",
    "res = pd.concat(all_rows, ignore_index=True)\n",
    "out_csv = os.path.join(FREEZE_DIR, \"experiments_unsup_guided_results.csv\")\n",
    "res.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nResultados salvos em:\", out_csv)\n",
    "print(\"Modelos salvos:\")\n",
    "for n, p in models_paths:\n",
    "    print(\" -\", n, \"=>\", p)\n",
    "\n",
    "# visão rápida: ordenar por desempenho em TESTE (Wm)\n",
    "display(res[res[\"split\"]==\"teste\"].sort_values(\"R2_wm_kg_m2_h\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2726dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\E4_regime_lags_reweight_HGBR_abs_20250818_0845.joblib\n",
      "Resultados anexados em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\experiments_unsup_guided_results.csv\n",
      "\n",
      "== COMPARATIVO (split=teste) — ordenado por R2 de Wm ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "exp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R2_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "74f7df7e-a10f-416d-9cc4-2f398f0b0e58",
       "rows": [
        [
         "2",
         "E4_regime_lags_reweight_HGBR_abs",
         "teste",
         "-0.47243371229910713",
         "2.6812259597528087e-07",
         "-0.6888586613209562",
         "150422.5603571368"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>split</th>\n",
       "      <th>R2_wr_kg_m2_h</th>\n",
       "      <th>MAE_wr_kg_m2_h</th>\n",
       "      <th>R2_wm_kg_m2_h</th>\n",
       "      <th>MAE_wm_kg_m2_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E4_regime_lags_reweight_HGBR_abs</td>\n",
       "      <td>teste</td>\n",
       "      <td>-0.472434</td>\n",
       "      <td>2.681226e-07</td>\n",
       "      <td>-0.688859</td>\n",
       "      <td>150422.560357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                exp  split  R2_wr_kg_m2_h  MAE_wr_kg_m2_h  \\\n",
       "2  E4_regime_lags_reweight_HGBR_abs  teste      -0.472434    2.681226e-07   \n",
       "\n",
       "   R2_wm_kg_m2_h  MAE_wm_kg_m2_h  \n",
       "2      -0.688859   150422.560357  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================\n",
    "# MINI: Reexecuta somente E4 com estimador escolhido\n",
    "# ============================\n",
    "import os, json, joblib, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import iqr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\n",
    "\n",
    "# ---- escolha: 'hist_absolute' | 'hist_quantile' | 'gbr_huber'\n",
    "CHOICE = \"hist_absolute\"  # <<< MUDE AQUI SE QUISER\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "PATH_FEATS_GOLD = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\")\n",
    "PATH_SPLITS     = os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\")\n",
    "PATH_KLAB       = os.path.join(FREEZE_DIR, \"kmeans_labels.csv\")\n",
    "PATH_XAUG       = os.path.join(FREEZE_DIR, \"X_augmented_preview.csv\")\n",
    "PATH_RES_ALL    = os.path.join(FREEZE_DIR, \"experiments_unsup_guided_results.csv\")\n",
    "os.makedirs(os.path.join(FREEZE_DIR, \"models\"), exist_ok=True)\n",
    "\n",
    "# ---- dados base e splits\n",
    "dfr = pd.read_csv(PATH_FEATS_GOLD, header=[0,1], engine=\"python\")\n",
    "df  = dfr.copy(); df.columns = [c for (c,_) in dfr.columns]\n",
    "timestamp = pd.to_datetime(df.iloc[:,0], errors=\"coerce\")\n",
    "YCOLS = [\"wr_kg_m2_h\", \"wm_kg_m2_h\"]\n",
    "X_base = df.drop(columns=YCOLS).select_dtypes(include=[np.number]).copy()\n",
    "y_all  = df[YCOLS].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "\n",
    "splits = joblib.load(PATH_SPLITS)\n",
    "idx_tr, idx_va, idx_te = splits[\"train\"], splits[\"val\"], splits[\"test\"]\n",
    "\n",
    "# ---- features E4 (regime + distâncias + lags)\n",
    "X_aug = pd.read_csv(PATH_XAUG)\n",
    "lag_cols = [c for c in X_aug.columns if c.startswith(\"lag\")]\n",
    "reg_cols = [c for c in X_aug.columns if c.startswith(\"kmeans_c_\") or c.startswith(\"kmeans_dist_\")]\n",
    "X_E4 = pd.concat([X_base, X_aug[reg_cols + lag_cols]], axis=1)\n",
    "\n",
    "# ---- reweight por cluster (aproxima treino do teste)\n",
    "klabels  = pd.read_csv(PATH_KLAB)\n",
    "clusters = klabels[\"cluster\"].astype(int).values\n",
    "c_tr = clusters[idx_tr]; c_te = clusters[idx_te]\n",
    "uniq = np.unique(np.concatenate([c_tr, c_te]))\n",
    "p_tr = {c: max(1e-6, (c_tr==c).mean()) for c in uniq}\n",
    "p_te = {c:        (c_te==c).mean()     for c in uniq}\n",
    "wmap = {c: p_te[c]/p_tr[c] for c in uniq}\n",
    "sw = np.array([wmap.get(c, 1.0) for c in c_tr], dtype=float)\n",
    "sw = sw * (len(sw)/sw.sum())  # normaliza média ~1\n",
    "\n",
    "# ---- split dos dados\n",
    "X_tr = X_E4.iloc[idx_tr]; X_va = X_E4.iloc[idx_va]; X_te = X_E4.iloc[idx_te]\n",
    "y_tr = y_all[idx_tr];      y_va = y_all[idx_va];      y_te = y_all[idx_te]\n",
    "\n",
    "# ---- imputer+scaler (treina no treino)\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "sc  = StandardScaler()\n",
    "X_tr_p = sc.fit_transform(imp.fit_transform(X_tr))\n",
    "X_va_p = sc.transform(imp.transform(X_va))\n",
    "X_te_p = sc.transform(imp.transform(X_te))\n",
    "\n",
    "# ---- escolhe estimador\n",
    "if CHOICE == \"hist_absolute\":\n",
    "    base = HistGradientBoostingRegressor(loss=\"absolute_error\", random_state=42)\n",
    "    exp_name = \"E4_regime_lags_reweight_HGBR_abs\"\n",
    "elif CHOICE == \"hist_quantile\":\n",
    "    base = HistGradientBoostingRegressor(loss=\"quantile\", quantile=0.5, random_state=42)\n",
    "    exp_name = \"E4_regime_lags_reweight_HGBR_q50\"\n",
    "elif CHOICE == \"gbr_huber\":\n",
    "    base = GradientBoostingRegressor(loss=\"huber\", alpha=0.9, random_state=42)\n",
    "    exp_name = \"E4_regime_lags_reweight_GBR_huber\"\n",
    "else:\n",
    "    raise ValueError(\"CHOICE inválido.\")\n",
    "\n",
    "est = MultiOutputRegressor(base)\n",
    "\n",
    "# ---- fit\n",
    "est.fit(X_tr_p, y_tr, sample_weight=sw)\n",
    "\n",
    "# ---- preds e métricas\n",
    "def mae_iqr(y_true, y_pred):\n",
    "    e = np.abs(y_true - y_pred); den = iqr(y_true) or 1.0\n",
    "    return float(np.mean(e)/den)\n",
    "\n",
    "def resumo(exp, split_name, idx, y, yhat, tstamp):\n",
    "    r = {\"exp\": exp, \"split\": split_name, \"linhas\": int(len(idx))}\n",
    "    r[\"inicio\"] = str(pd.to_datetime(tstamp.iloc[idx].min()))\n",
    "    r[\"fim\"]    = str(pd.to_datetime(tstamp.iloc[idx].max()))\n",
    "    for j, alvo in enumerate(YCOLS):\n",
    "        yt, yp = y[:,j], yhat[:,j]\n",
    "        r[f\"R2_{alvo}\"]      = float(r2_score(yt, yp)) if np.var(yt) > 0 else np.nan\n",
    "        r[f\"RMSE_{alvo}\"]    = float(mean_squared_error(yt, yp) ** 0.5)\n",
    "        r[f\"MAE_{alvo}\"]     = float(mean_absolute_error(yt, yp))\n",
    "        r[f\"MAE_IQR_{alvo}\"] = float(mae_iqr(yt, yp))\n",
    "    return r\n",
    "\n",
    "yhat_tr = est.predict(X_tr_p)\n",
    "yhat_va = est.predict(X_va_p)\n",
    "yhat_te = est.predict(X_te_p)\n",
    "\n",
    "rows = []\n",
    "rows.append(resumo(exp_name, \"treino\",    idx_tr, y_tr, yhat_tr, timestamp))\n",
    "rows.append(resumo(exp_name, \"validacao\", idx_va, y_va, yhat_va, timestamp))\n",
    "rows.append(resumo(exp_name, \"teste\",     idx_te, y_te, yhat_te, timestamp))\n",
    "df_new = pd.DataFrame(rows)\n",
    "\n",
    "# ---- persiste modelo e anexa resultados\n",
    "tag = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "mpath = os.path.join(FREEZE_DIR, \"models\", f\"{exp_name}_{tag}.joblib\")\n",
    "joblib.dump({\"model\": est, \"imputer\": imp, \"scaler\": sc, \"y_names\": YCOLS, \"features\": list(X_E4.columns)}, mpath)\n",
    "\n",
    "if os.path.exists(PATH_RES_ALL):\n",
    "    df_all = pd.read_csv(PATH_RES_ALL)\n",
    "    df_all = pd.concat([df_all, df_new], ignore_index=True)\n",
    "else:\n",
    "    df_all = df_new.copy()\n",
    "df_all.to_csv(PATH_RES_ALL, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Modelo salvo em:\", mpath)\n",
    "print(\"Resultados anexados em:\", PATH_RES_ALL)\n",
    "\n",
    "# ---- comparativo só TESTE\n",
    "print(\"\\n== COMPARATIVO (split=teste) — ordenado por R2 de Wm ==\")\n",
    "cols_show = [\"exp\",\"split\",\"R2_wr_kg_m2_h\",\"MAE_wr_kg_m2_h\",\"R2_wm_kg_m2_h\",\"MAE_wm_kg_m2_h\"]\n",
    "disp = df_all[df_all[\"split\"]==\"teste\"][cols_show].sort_values(\"R2_wm_kg_m2_h\", ascending=False)\n",
    "display(disp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ae18782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\E4_regime_lags_reweight_GBR_huber_20250818_0847.joblib\n",
      "Resultados anexados em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\experiments_unsup_guided_results.csv\n",
      "\n",
      "== COMPARATIVO (split=teste) — ordenado por R2 de Wm ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "exp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R2_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "97fa8f7e-cdbb-434b-a696-16851bf2baec",
       "rows": [
        [
         "5",
         "E4_regime_lags_reweight_GBR_huber",
         "teste",
         "-0.46653710935984494",
         "2.6827864806432483e-07",
         "0.6475188367152105",
         "65209.48308693358"
        ],
        [
         "2",
         "E4_regime_lags_reweight_HGBR_abs",
         "teste",
         "-0.4724337122991071",
         "2.681225959752809e-07",
         "-0.6888586613209562",
         "150422.5603571368"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>split</th>\n",
       "      <th>R2_wr_kg_m2_h</th>\n",
       "      <th>MAE_wr_kg_m2_h</th>\n",
       "      <th>R2_wm_kg_m2_h</th>\n",
       "      <th>MAE_wm_kg_m2_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E4_regime_lags_reweight_GBR_huber</td>\n",
       "      <td>teste</td>\n",
       "      <td>-0.466537</td>\n",
       "      <td>2.682786e-07</td>\n",
       "      <td>0.647519</td>\n",
       "      <td>65209.483087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E4_regime_lags_reweight_HGBR_abs</td>\n",
       "      <td>teste</td>\n",
       "      <td>-0.472434</td>\n",
       "      <td>2.681226e-07</td>\n",
       "      <td>-0.688859</td>\n",
       "      <td>150422.560357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 exp  split  R2_wr_kg_m2_h  MAE_wr_kg_m2_h  \\\n",
       "5  E4_regime_lags_reweight_GBR_huber  teste      -0.466537    2.682786e-07   \n",
       "2   E4_regime_lags_reweight_HGBR_abs  teste      -0.472434    2.681226e-07   \n",
       "\n",
       "   R2_wm_kg_m2_h  MAE_wm_kg_m2_h  \n",
       "5       0.647519    65209.483087  \n",
       "2      -0.688859   150422.560357  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================\n",
    "# MINI: Reexecuta somente E4 com estimador escolhido\n",
    "# ============================\n",
    "import os, json, joblib, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import iqr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor\n",
    "\n",
    "# ---- escolha: 'hist_absolute' | 'hist_quantile' | 'gbr_huber'\n",
    "CHOICE = \"gbr_huber\"  # <<< MUDE AQUI SE QUISER\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "PATH_FEATS_GOLD = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\")\n",
    "PATH_SPLITS     = os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\")\n",
    "PATH_KLAB       = os.path.join(FREEZE_DIR, \"kmeans_labels.csv\")\n",
    "PATH_XAUG       = os.path.join(FREEZE_DIR, \"X_augmented_preview.csv\")\n",
    "PATH_RES_ALL    = os.path.join(FREEZE_DIR, \"experiments_unsup_guided_results.csv\")\n",
    "os.makedirs(os.path.join(FREEZE_DIR, \"models\"), exist_ok=True)\n",
    "\n",
    "# ---- dados base e splits\n",
    "dfr = pd.read_csv(PATH_FEATS_GOLD, header=[0,1], engine=\"python\")\n",
    "df  = dfr.copy(); df.columns = [c for (c,_) in dfr.columns]\n",
    "timestamp = pd.to_datetime(df.iloc[:,0], errors=\"coerce\")\n",
    "YCOLS = [\"wr_kg_m2_h\", \"wm_kg_m2_h\"]\n",
    "X_base = df.drop(columns=YCOLS).select_dtypes(include=[np.number]).copy()\n",
    "y_all  = df[YCOLS].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "\n",
    "splits = joblib.load(PATH_SPLITS)\n",
    "idx_tr, idx_va, idx_te = splits[\"train\"], splits[\"val\"], splits[\"test\"]\n",
    "\n",
    "# ---- features E4 (regime + distâncias + lags)\n",
    "X_aug = pd.read_csv(PATH_XAUG)\n",
    "lag_cols = [c for c in X_aug.columns if c.startswith(\"lag\")]\n",
    "reg_cols = [c for c in X_aug.columns if c.startswith(\"kmeans_c_\") or c.startswith(\"kmeans_dist_\")]\n",
    "X_E4 = pd.concat([X_base, X_aug[reg_cols + lag_cols]], axis=1)\n",
    "\n",
    "# ---- reweight por cluster (aproxima treino do teste)\n",
    "klabels  = pd.read_csv(PATH_KLAB)\n",
    "clusters = klabels[\"cluster\"].astype(int).values\n",
    "c_tr = clusters[idx_tr]; c_te = clusters[idx_te]\n",
    "uniq = np.unique(np.concatenate([c_tr, c_te]))\n",
    "p_tr = {c: max(1e-6, (c_tr==c).mean()) for c in uniq}\n",
    "p_te = {c:        (c_te==c).mean()     for c in uniq}\n",
    "wmap = {c: p_te[c]/p_tr[c] for c in uniq}\n",
    "sw = np.array([wmap.get(c, 1.0) for c in c_tr], dtype=float)\n",
    "sw = sw * (len(sw)/sw.sum())  # normaliza média ~1\n",
    "\n",
    "# ---- split dos dados\n",
    "X_tr = X_E4.iloc[idx_tr]; X_va = X_E4.iloc[idx_va]; X_te = X_E4.iloc[idx_te]\n",
    "y_tr = y_all[idx_tr];      y_va = y_all[idx_va];      y_te = y_all[idx_te]\n",
    "\n",
    "# ---- imputer+scaler (treina no treino)\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "sc  = StandardScaler()\n",
    "X_tr_p = sc.fit_transform(imp.fit_transform(X_tr))\n",
    "X_va_p = sc.transform(imp.transform(X_va))\n",
    "X_te_p = sc.transform(imp.transform(X_te))\n",
    "\n",
    "# ---- escolhe estimador\n",
    "if CHOICE == \"hist_absolute\":\n",
    "    base = HistGradientBoostingRegressor(loss=\"absolute_error\", random_state=42)\n",
    "    exp_name = \"E4_regime_lags_reweight_HGBR_abs\"\n",
    "elif CHOICE == \"hist_quantile\":\n",
    "    base = HistGradientBoostingRegressor(loss=\"quantile\", quantile=0.5, random_state=42)\n",
    "    exp_name = \"E4_regime_lags_reweight_HGBR_q50\"\n",
    "elif CHOICE == \"gbr_huber\":\n",
    "    base = GradientBoostingRegressor(loss=\"huber\", alpha=0.9, random_state=42)\n",
    "    exp_name = \"E4_regime_lags_reweight_GBR_huber\"\n",
    "else:\n",
    "    raise ValueError(\"CHOICE inválido.\")\n",
    "\n",
    "est = MultiOutputRegressor(base)\n",
    "\n",
    "# ---- fit\n",
    "est.fit(X_tr_p, y_tr, sample_weight=sw)\n",
    "\n",
    "# ---- preds e métricas\n",
    "def mae_iqr(y_true, y_pred):\n",
    "    e = np.abs(y_true - y_pred); den = iqr(y_true) or 1.0\n",
    "    return float(np.mean(e)/den)\n",
    "\n",
    "def resumo(exp, split_name, idx, y, yhat, tstamp):\n",
    "    r = {\"exp\": exp, \"split\": split_name, \"linhas\": int(len(idx))}\n",
    "    r[\"inicio\"] = str(pd.to_datetime(tstamp.iloc[idx].min()))\n",
    "    r[\"fim\"]    = str(pd.to_datetime(tstamp.iloc[idx].max()))\n",
    "    for j, alvo in enumerate(YCOLS):\n",
    "        yt, yp = y[:,j], yhat[:,j]\n",
    "        r[f\"R2_{alvo}\"]      = float(r2_score(yt, yp)) if np.var(yt) > 0 else np.nan\n",
    "        r[f\"RMSE_{alvo}\"]    = float(mean_squared_error(yt, yp) ** 0.5)\n",
    "        r[f\"MAE_{alvo}\"]     = float(mean_absolute_error(yt, yp))\n",
    "        r[f\"MAE_IQR_{alvo}\"] = float(mae_iqr(yt, yp))\n",
    "    return r\n",
    "\n",
    "yhat_tr = est.predict(X_tr_p)\n",
    "yhat_va = est.predict(X_va_p)\n",
    "yhat_te = est.predict(X_te_p)\n",
    "\n",
    "rows = []\n",
    "rows.append(resumo(exp_name, \"treino\",    idx_tr, y_tr, yhat_tr, timestamp))\n",
    "rows.append(resumo(exp_name, \"validacao\", idx_va, y_va, yhat_va, timestamp))\n",
    "rows.append(resumo(exp_name, \"teste\",     idx_te, y_te, yhat_te, timestamp))\n",
    "df_new = pd.DataFrame(rows)\n",
    "\n",
    "# ---- persiste modelo e anexa resultados\n",
    "tag = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "mpath = os.path.join(FREEZE_DIR, \"models\", f\"{exp_name}_{tag}.joblib\")\n",
    "joblib.dump({\"model\": est, \"imputer\": imp, \"scaler\": sc, \"y_names\": YCOLS, \"features\": list(X_E4.columns)}, mpath)\n",
    "\n",
    "if os.path.exists(PATH_RES_ALL):\n",
    "    df_all = pd.read_csv(PATH_RES_ALL)\n",
    "    df_all = pd.concat([df_all, df_new], ignore_index=True)\n",
    "else:\n",
    "    df_all = df_new.copy()\n",
    "df_all.to_csv(PATH_RES_ALL, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Modelo salvo em:\", mpath)\n",
    "print(\"Resultados anexados em:\", PATH_RES_ALL)\n",
    "\n",
    "# ---- comparativo só TESTE\n",
    "print(\"\\n== COMPARATIVO (split=teste) — ordenado por R2 de Wm ==\")\n",
    "cols_show = [\"exp\",\"split\",\"R2_wr_kg_m2_h\",\"MAE_wr_kg_m2_h\",\"R2_wm_kg_m2_h\",\"MAE_wm_kg_m2_h\"]\n",
    "disp = df_all[df_all[\"split\"]==\"teste\"][cols_show].sort_values(\"R2_wm_kg_m2_h\", ascending=False)\n",
    "display(disp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d60135c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Não encontrei linha de baseline (E0_baseline_RF) no CSV de resultados.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m base = dft[dft[\u001b[33m\"\u001b[39m\u001b[33mexp\u001b[39m\u001b[33m\"\u001b[39m].str.contains(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mbE0_baseline_RF\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m, regex=\u001b[38;5;28;01mTrue\u001b[39;00m)].copy()\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base.empty:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNão encontrei linha de baseline (E0_baseline_RF) no CSV de resultados.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m base = base.iloc[\u001b[32m0\u001b[39m]\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# métricas que vamos usar\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Não encontrei linha de baseline (E0_baseline_RF) no CSV de resultados."
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SELEÇÃO AUTOMÁTICA DO MVP (a partir dos resultados já gerados)\n",
    "# ============================================================\n",
    "import os, re, glob, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ==== PARÂMETROS (ajuste se quiser) ====\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "\n",
    "# alvo e split primário\n",
    "PRIMARY_TARGET = \"wm_kg_m2_h\"\n",
    "PRIMARY_SPLIT  = \"teste\"\n",
    "\n",
    "# restrições para Wr (não degradar demais)\n",
    "ALLOW_WR_R2_DROP = 0.02     # Wr: queda máxima de R² vs baseline E0\n",
    "ALLOW_WR_MAE_INC = 0.15     # Wr: aumento máximo de MAE vs baseline E0 (15%)\n",
    "\n",
    "# se existir tabela por cluster, usar este cluster como foco\n",
    "USE_CLUSTER_SELECTION = True\n",
    "FOCUS_CLUSTER = 1\n",
    "\n",
    "# ==== CARREGA RESULTADOS ====\n",
    "res_path = os.path.join(FREEZE_DIR, \"experiments_unsup_guided_results.csv\")\n",
    "df = pd.read_csv(res_path)\n",
    "\n",
    "# filtra apenas o split de interesse\n",
    "dft = df[df[\"split\"].str.lower()==PRIMARY_SPLIT.lower()].copy()\n",
    "\n",
    "# baseline E0 (referência de restrição em Wr)\n",
    "base = dft[dft[\"exp\"].str.contains(r\"\\bE0_baseline_RF\\b\", regex=True)].copy()\n",
    "if base.empty:\n",
    "    raise RuntimeError(\"Não encontrei linha de baseline (E0_baseline_RF) no CSV de resultados.\")\n",
    "base = base.iloc[0]\n",
    "\n",
    "# métricas que vamos usar\n",
    "R2_wr = \"R2_wr_kg_m2_h\"\n",
    "MAE_wr = \"MAE_wr_kg_m2_h\"\n",
    "R2_wm = \"R2_wm_kg_m2_h\"\n",
    "MAE_wm = \"MAE_wm_kg_m2_h\"\n",
    "\n",
    "# ==== A) SELEÇÃO GLOBAL (sem cluster) ====\n",
    "candidates = dft.copy()\n",
    "\n",
    "# restrições em Wr vs baseline\n",
    "candidates[\"ok_wr_r2\"]  = candidates[R2_wr] >= (float(base[R2_wr]) - ALLOW_WR_R2_DROP)\n",
    "candidates[\"ok_wr_mae\"] = candidates[MAE_wr] <= (float(base[MAE_wr]) * (1.0 + ALLOW_WR_MAE_INC))\n",
    "candidates[\"ok_all\"]    = candidates[\"ok_wr_r2\"] & candidates[\"ok_wr_mae\"]\n",
    "\n",
    "# rank primário: MAE_wm asc, desempate por R2_wm desc\n",
    "cand_ok = candidates[candidates[\"ok_all\"]].copy()\n",
    "cand_ok = cand_ok.sort_values([MAE_wm, R2_wm], ascending=[True, False])\n",
    "\n",
    "# pega top-5 e o vencedor\n",
    "top5_global = cand_ok.head(5).copy()\n",
    "winner_global = top5_global.iloc[0] if not top5_global.empty else None\n",
    "\n",
    "# ==== B) SELEÇÃO POR CLUSTER (se disponível) ====\n",
    "winner_cluster = None\n",
    "top5_cluster = None\n",
    "\n",
    "if USE_CLUSTER_SELECTION:\n",
    "    cl_path = os.path.join(FREEZE_DIR, \"metrics_by_cluster_kmeans.csv\")\n",
    "    if os.path.exists(cl_path):\n",
    "        dfc = pd.read_csv(cl_path)\n",
    "        dfc = dfc[dfc[\"split\"].str.lower()==PRIMARY_SPLIT.lower()].copy()\n",
    "        dfc = dfc[dfc[\"cluster\"]==FOCUS_CLUSTER].copy()\n",
    "\n",
    "        # vamos mapear cada experimento às suas métricas? -> aqui usamos o melhor global já escolhido\n",
    "        # como os experimentos não estão \"por cluster\" nesse CSV, a seleção por cluster serve de SANITY:\n",
    "        # mostramos o baseline e o melhor global para o cluster 1.\n",
    "        # (Se você preferir selecionar por cluster estritamente, precisamos gerar métricas por cluster para cada experimento.)\n",
    "        # Por ora, só confirmamos baseline vs baseline (já está no CSV por cluster) e comparamos com o melhor global, se existir.\n",
    "\n",
    "        # baseline cluster:\n",
    "        base_cl = dfc.copy()  # contém apenas baseline? -> nosso CSV por cluster foi do baseline; mostrar ranking do cluster pode não fazer sentido para todos exp.\n",
    "        # então apenas guardamos para exibição:\n",
    "        top5_cluster = dfc.sort_values([\"R2_wm\",\"MAE_wm\"], ascending=[False, True]).head(5).copy()\n",
    "    else:\n",
    "        print(\"Aviso: 'metrics_by_cluster_kmeans.csv' não encontrado — pulando análise por cluster.\")\n",
    "\n",
    "# ==== LOCALIZA O ARQUIVO DO MODELO DO VENCEDOR ====\n",
    "def find_model_file(exp_name):\n",
    "    mdir = os.path.join(FREEZE_DIR, \"models\")\n",
    "    # procura arquivos que começam com o nome do experimento\n",
    "    patt = os.path.join(mdir, f\"{exp_name}_*.joblib\")\n",
    "    files = glob.glob(patt)\n",
    "    if not files:\n",
    "        return None\n",
    "    # escolhe o mais recente\n",
    "    files.sort(key=os.path.getmtime, reverse=True)\n",
    "    return files[0]\n",
    "\n",
    "selected = {}\n",
    "if winner_global is not None:\n",
    "    exp_name = str(winner_global[\"exp\"])\n",
    "    selected[\"exp\"] = exp_name\n",
    "    selected[\"criterion\"] = \"global_min_MAE_wm_then_max_R2_wm_with_WR_constraints\"\n",
    "    selected[\"model_path\"] = find_model_file(exp_name)\n",
    "    selected[\"metrics_test\"] = {\n",
    "        \"R2_wr\": float(winner_global[R2_wr]),\n",
    "        \"MAE_wr\": float(winner_global[MAE_wr]),\n",
    "        \"R2_wm\": float(winner_global[R2_wm]),\n",
    "        \"MAE_wm\": float(winner_global[MAE_wm]),\n",
    "    }\n",
    "\n",
    "# ==== MOSTRA RELATÓRIO ====\n",
    "print(\"=== BASELINE (E0) — TESTE ===\")\n",
    "print(f\"R2_wr={base[R2_wr]:.6f}  | MAE_wr={base[MAE_wr]:.6g} | R2_wm={base[R2_wm]:.6f} | MAE_wm={base[MAE_wm]:.6g}\\n\")\n",
    "\n",
    "print(\"=== TOP-5 CANDIDATOS (GLOBAL, restrições de WR ativas) — TESTE ===\")\n",
    "display(top5_global[[ \"exp\", R2_wr, MAE_wr, R2_wm, MAE_wm, \"ok_wr_r2\", \"ok_wr_mae\"]])\n",
    "\n",
    "if top5_cluster is not None:\n",
    "    print(\"\\n=== (INFO) CLUSTER 1 — TOP-5 (baseline metrics_by_cluster_kmeans.csv) ===\")\n",
    "    display(top5_cluster)\n",
    "\n",
    "print(\"\\n=== ESCOLHA RECOMENDADA (GLOBAL) ===\")\n",
    "if selected:\n",
    "    print(json.dumps(selected, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(\"Nenhum candidato atende às restrições. Considere afrouxar ALLOW_WR_R2_DROP / ALLOW_WR_MAE_INC.\")\n",
    "\n",
    "# salva a escolha em JSON para rastreabilidade\n",
    "with open(os.path.join(FREEZE_DIR, \"mvp_selection.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(selected, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbd3a65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Rodando E0_baseline_RF | cols=144 | reweight=False | hgbr=False\n",
      "==> Rodando E1_regime_RF | cols=148 | reweight=False | hgbr=False\n",
      "==> Rodando E2_regime_reweight_RF | cols=148 | reweight=True | hgbr=False\n",
      "==> Rodando E3_regime_lags_reweight_RF | cols=198 | reweight=True | hgbr=False\n",
      "==> Rodando E4_regime_lags_reweight_HGBR | cols=198 | reweight=True | hgbr=True\n",
      "\n",
      "Resultados salvos em: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\experiments_unsup_guided_results.csv\n",
      "Modelos salvos:\n",
      " - E0_baseline_RF => C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\E0_baseline_RF_20250818_0858.joblib\n",
      " - E1_regime_RF => C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\E1_regime_RF_20250818_0859.joblib\n",
      " - E2_regime_reweight_RF => C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\E2_regime_reweight_RF_20250818_0859.joblib\n",
      " - E3_regime_lags_reweight_RF => C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\E3_regime_lags_reweight_RF_20250818_0900.joblib\n",
      " - E4_regime_lags_reweight_HGBR => C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\E4_regime_lags_reweight_HGBR_20250818_0900.joblib\n",
      "\n",
      "== COMPARATIVO (split=teste) ==\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "exp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "R2_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wr_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R2_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_wm_kg_m2_h",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6c6bafdc-911d-4b57-9aee-ff011632e591",
       "rows": [
        [
         "2",
         "E0_baseline_RF",
         "teste",
         "0.7555313839613604",
         "1.0838959098182045e-07",
         "0.6977987427390622",
         "58664.260830891195"
        ],
        [
         "5",
         "E1_regime_RF",
         "teste",
         "0.7580614622147781",
         "1.0841528402581708e-07",
         "0.6959841603294292",
         "58781.950326093924"
        ],
        [
         "8",
         "E2_regime_reweight_RF",
         "teste",
         "0.508760900742105",
         "1.3743661707474735e-07",
         "0.6780057380158785",
         "58548.80872616989"
        ],
        [
         "11",
         "E3_regime_lags_reweight_RF",
         "teste",
         "0.48182586026576646",
         "1.4114219524759205e-07",
         "0.6557579745806728",
         "60415.82242039525"
        ],
        [
         "14",
         "E4_regime_lags_reweight_HGBR",
         "teste",
         "-0.47243371229910713",
         "2.6812259597528087e-07",
         "-0.6888586613209562",
         "150422.5603571368"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>split</th>\n",
       "      <th>R2_wr_kg_m2_h</th>\n",
       "      <th>MAE_wr_kg_m2_h</th>\n",
       "      <th>R2_wm_kg_m2_h</th>\n",
       "      <th>MAE_wm_kg_m2_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0_baseline_RF</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.755531</td>\n",
       "      <td>1.083896e-07</td>\n",
       "      <td>0.697799</td>\n",
       "      <td>58664.260831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E1_regime_RF</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.758061</td>\n",
       "      <td>1.084153e-07</td>\n",
       "      <td>0.695984</td>\n",
       "      <td>58781.950326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E2_regime_reweight_RF</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.508761</td>\n",
       "      <td>1.374366e-07</td>\n",
       "      <td>0.678006</td>\n",
       "      <td>58548.808726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E3_regime_lags_reweight_RF</td>\n",
       "      <td>teste</td>\n",
       "      <td>0.481826</td>\n",
       "      <td>1.411422e-07</td>\n",
       "      <td>0.655758</td>\n",
       "      <td>60415.822420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E4_regime_lags_reweight_HGBR</td>\n",
       "      <td>teste</td>\n",
       "      <td>-0.472434</td>\n",
       "      <td>2.681226e-07</td>\n",
       "      <td>-0.688859</td>\n",
       "      <td>150422.560357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             exp  split  R2_wr_kg_m2_h  MAE_wr_kg_m2_h  \\\n",
       "2                 E0_baseline_RF  teste       0.755531    1.083896e-07   \n",
       "5                   E1_regime_RF  teste       0.758061    1.084153e-07   \n",
       "8          E2_regime_reweight_RF  teste       0.508761    1.374366e-07   \n",
       "11    E3_regime_lags_reweight_RF  teste       0.481826    1.411422e-07   \n",
       "14  E4_regime_lags_reweight_HGBR  teste      -0.472434    2.681226e-07   \n",
       "\n",
       "    R2_wm_kg_m2_h  MAE_wm_kg_m2_h  \n",
       "2        0.697799    58664.260831  \n",
       "5        0.695984    58781.950326  \n",
       "8        0.678006    58548.808726  \n",
       "11       0.655758    60415.822420  \n",
       "14      -0.688859   150422.560357  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# RE-RUN COMPLETO: E0..E4 (E4 = HistGBR absolute_error)\n",
    "# ============================================================\n",
    "import os, json, glob, joblib, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import iqr\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "# ---------- PARÂMETROS ----------\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "PATH_FEATS_GOLD = os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\")\n",
    "PATH_SPLITS     = os.path.join(FREEZE_DIR, \"splits_gold_70_10_20.joblib\")\n",
    "PATH_KLAB       = os.path.join(FREEZE_DIR, \"kmeans_labels.csv\")\n",
    "PATH_KCENT      = os.path.join(FREEZE_DIR, \"kmeans_centroids_pcspace.csv\")\n",
    "PATH_PCSCORES   = os.path.join(FREEZE_DIR, \"pca_scores.csv\")\n",
    "PATH_DRIFT      = os.path.join(FREEZE_DIR, \"drift_psi_ks_train_vs_test.csv\")\n",
    "OUT_MODELS_DIR  = os.path.join(FREEZE_DIR, \"models\")\n",
    "OUT_RESULTS     = os.path.join(FREEZE_DIR, \"experiments_unsup_guided_results.csv\")\n",
    "\n",
    "os.makedirs(OUT_MODELS_DIR, exist_ok=True)\n",
    "\n",
    "YCOLS = [\"wr_kg_m2_h\",\"wm_kg_m2_h\"]\n",
    "LAG_HOURS = [1,3,6,12,24]\n",
    "TOP_PSI_LAGS = 10   # top-N features por PSI para gerar lags\n",
    "\n",
    "# ---------- UTILIDADES ----------\n",
    "def mae_iqr(y_true, y_pred):\n",
    "    e = np.abs(y_true - y_pred); den = iqr(y_true) or 1.0\n",
    "    return float(np.mean(e)/den)\n",
    "\n",
    "def resumo(exp, split_name, idx, y, yhat, tstamp):\n",
    "    r = {\"exp\": exp, \"split\": split_name, \"linhas\": int(len(idx))}\n",
    "    r[\"inicio\"] = str(pd.to_datetime(tstamp.iloc[idx].min()))\n",
    "    r[\"fim\"]    = str(pd.to_datetime(tstamp.iloc[idx].max()))\n",
    "    for j, alvo in enumerate(YCOLS):\n",
    "        yt, yp = y[:,j], yhat[:,j]\n",
    "        r[f\"R2_{alvo}\"]      = float(r2_score(yt, yp)) if np.var(yt) > 0 else np.nan\n",
    "        r[f\"RMSE_{alvo}\"]    = float(mean_squared_error(yt, yp) ** 0.5)\n",
    "        r[f\"MAE_{alvo}\"]     = float(mean_absolute_error(yt, yp))\n",
    "        r[f\"MAE_IQR_{alvo}\"] = float(mae_iqr(yt, yp))\n",
    "    return r\n",
    "\n",
    "def fit_eval(nome_exp, Xall, yall, idx_tr, idx_va, idx_te, timestamp, clusters=None, reweight=False, estimator=\"rf\"):\n",
    "    # splits\n",
    "    X_tr = Xall.iloc[idx_tr]; X_va = Xall.iloc[idx_va]; X_te = Xall.iloc[idx_te]\n",
    "    y_tr = yall[idx_tr];      y_va = yall[idx_va];      y_te = yall[idx_te]\n",
    "\n",
    "    # pipeline\n",
    "    imp = SimpleImputer(strategy=\"median\")\n",
    "    sc  = StandardScaler()\n",
    "    X_tr_p = sc.fit_transform(imp.fit_transform(X_tr))\n",
    "    X_va_p = sc.transform(imp.transform(X_va))\n",
    "    X_te_p = sc.transform(imp.transform(X_te))\n",
    "\n",
    "    # estimador\n",
    "    if estimator == \"rf\":\n",
    "        base = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "    elif estimator == \"hgbr_abs\":\n",
    "        base = HistGradientBoostingRegressor(loss=\"absolute_error\", random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"estimador inválido.\")\n",
    "    est = MultiOutputRegressor(base)\n",
    "\n",
    "    # pesos por cluster (reponderação)\n",
    "    fit_kwargs = {}\n",
    "    if reweight and clusters is not None:\n",
    "        c_tr = clusters[idx_tr]; c_te = clusters[idx_te]\n",
    "        uniq = np.unique(np.concatenate([c_tr, c_te]))\n",
    "        p_tr = {c: max(1e-6, (c_tr==c).mean()) for c in uniq}\n",
    "        p_te = {c:        (c_te==c).mean()     for c in uniq}\n",
    "        wmap = {c: p_te[c]/p_tr[c] for c in uniq}\n",
    "        sw = np.array([wmap.get(c, 1.0) for c in c_tr], dtype=float)\n",
    "        sw = sw * (len(sw)/sw.sum())  # média ~1\n",
    "        fit_kwargs[\"sample_weight\"] = sw\n",
    "\n",
    "    # treino\n",
    "    est.fit(X_tr_p, y_tr, **fit_kwargs)\n",
    "\n",
    "    # predições\n",
    "    yhat_tr = est.predict(X_tr_p)\n",
    "    yhat_va = est.predict(X_va_p)\n",
    "    yhat_te = est.predict(X_te_p)\n",
    "\n",
    "    # métricas\n",
    "    rows = [\n",
    "        resumo(nome_exp, \"treino\",    idx_tr, y_tr, yhat_tr, timestamp),\n",
    "        resumo(nome_exp, \"validacao\", idx_va, y_va, yhat_va, timestamp),\n",
    "        resumo(nome_exp, \"teste\",     idx_te, y_te, yhat_te, timestamp),\n",
    "    ]\n",
    "\n",
    "    # persistência do modelo\n",
    "    tag = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "    mpath = os.path.join(OUT_MODELS_DIR, f\"{nome_exp}_{tag}.joblib\")\n",
    "    joblib.dump({\"model\": est, \"imputer\": imp, \"scaler\": sc, \"y_names\": YCOLS, \"features\": list(Xall.columns)}, mpath)\n",
    "\n",
    "    return pd.DataFrame(rows), mpath\n",
    "\n",
    "# ---------- LOAD DADOS BASE ----------\n",
    "dfr = pd.read_csv(PATH_FEATS_GOLD, header=[0,1], engine=\"python\")\n",
    "df  = dfr.copy(); df.columns = [c for (c,_) in dfr.columns]\n",
    "timestamp = pd.to_datetime(df.iloc[:,0], errors=\"coerce\")\n",
    "\n",
    "# X base (sem alvos), y\n",
    "X_base = df.drop(columns=YCOLS).select_dtypes(include=[np.number]).copy()\n",
    "y_all  = df[YCOLS].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "\n",
    "# splits\n",
    "splits = joblib.load(PATH_SPLITS)\n",
    "idx_tr, idx_va, idx_te = splits[\"train\"], splits[\"val\"], splits[\"test\"]\n",
    "\n",
    "# ---------- RECONSTRUIR FEATURES (regime + distâncias + lags) ----------\n",
    "# rótulos KMeans\n",
    "klabels = pd.read_csv(PATH_KLAB)  # timestamp, split, kmeans_k, cluster\n",
    "clusters = klabels[\"cluster\"].astype(int).values\n",
    "\n",
    "# distâncias a centróides em PC-space\n",
    "kcent = pd.read_csv(PATH_KCENT)   # cluster, PC1..PCm\n",
    "pc_cols = [c for c in kcent.columns if c.startswith(\"PC\")]\n",
    "scores  = pd.read_csv(PATH_PCSCORES)  # timestamp, split, PC1..PCn\n",
    "assert len(scores) == len(df), \"pca_scores.csv não está alinhado às linhas do GOLD.\"\n",
    "\n",
    "pc_matrix = scores[pc_cols].values\n",
    "centroids = {int(row[\"cluster\"]): row[pc_cols].values for _, row in kcent.iterrows()}\n",
    "# one-hot de cluster\n",
    "X_regime = pd.get_dummies(clusters, prefix=\"kmeans_c\", dtype=float)\n",
    "for c in sorted(centroids.keys()):\n",
    "    col = f\"kmeans_c_{int(c)}\"\n",
    "    if col not in X_regime.columns:\n",
    "        X_regime[col] = 0.0\n",
    "X_regime = X_regime[sorted(X_regime.columns)].reset_index(drop=True)\n",
    "\n",
    "# distâncias\n",
    "dist_cols, dist_data = [], []\n",
    "for cl, ctr in sorted(centroids.items()):\n",
    "    d = np.linalg.norm(pc_matrix - ctr, axis=1)\n",
    "    dist_data.append(d)\n",
    "    dist_cols.append(f\"kmeans_dist_c{cl}\")\n",
    "X_dist = pd.DataFrame(np.vstack(dist_data).T, columns=dist_cols)\n",
    "\n",
    "# lags nas top-PSI\n",
    "drift = pd.read_csv(PATH_DRIFT).sort_values([\"psi_train_test\",\"ks_train_test\"], ascending=False)\n",
    "top_features = [f for f in drift[\"feature\"].tolist() if f in X_base.columns][:TOP_PSI_LAGS]\n",
    "X_lags = pd.DataFrame(index=X_base.index)\n",
    "for f in top_features:\n",
    "    for h in LAG_HOURS:\n",
    "        X_lags[f\"lag{h}h__{f}\"] = X_base[f].shift(h)\n",
    "\n",
    "# design matrices\n",
    "X_E0 = X_base.copy()\n",
    "X_E1 = pd.concat([X_base, X_regime, X_dist], axis=1)\n",
    "X_E2 = X_E1.copy()\n",
    "X_E3 = pd.concat([X_base, X_regime, X_dist, X_lags], axis=1)\n",
    "X_E4 = X_E3.copy()\n",
    "\n",
    "# ---------- LOG DE COLUNAS (para conferência) ----------\n",
    "print(f\"==> Rodando E0_baseline_RF | cols={X_E0.shape[1]} | reweight=False | hgbr=False\")\n",
    "print(f\"==> Rodando E1_regime_RF | cols={X_E1.shape[1]} | reweight=False | hgbr=False\")\n",
    "print(f\"==> Rodando E2_regime_reweight_RF | cols={X_E2.shape[1]} | reweight=True | hgbr=False\")\n",
    "print(f\"==> Rodando E3_regime_lags_reweight_RF | cols={X_E3.shape[1]} | reweight=True | hgbr=False\")\n",
    "print(f\"==> Rodando E4_regime_lags_reweight_HGBR | cols={X_E4.shape[1]} | reweight=True | hgbr=True\")\n",
    "\n",
    "# ---------- EXPERIMENTOS ----------\n",
    "experiments = [\n",
    "    (\"E0_baseline_RF\",               X_E0, False, \"rf\"),\n",
    "    (\"E1_regime_RF\",                 X_E1, False, \"rf\"),\n",
    "    (\"E2_regime_reweight_RF\",        X_E2, True,  \"rf\"),\n",
    "    (\"E3_regime_lags_reweight_RF\",   X_E3, True,  \"rf\"),\n",
    "    (\"E4_regime_lags_reweight_HGBR\", X_E4, True,  \"hgbr_abs\"),\n",
    "]\n",
    "\n",
    "rows_all = []\n",
    "model_paths = []\n",
    "\n",
    "for name, Xmat, rewt, estype in experiments:\n",
    "    dfm, mpath = fit_eval(\n",
    "        name, Xmat, y_all, idx_tr, idx_va, idx_te,\n",
    "        timestamp, clusters=clusters, reweight=rewt, estimator=estype\n",
    "    )\n",
    "    rows_all.append(dfm); model_paths.append((name, mpath))\n",
    "\n",
    "res = pd.concat(rows_all, ignore_index=True)\n",
    "\n",
    "# ---------- SALVAR RESULTADOS ----------\n",
    "res.to_csv(OUT_RESULTS, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nResultados salvos em:\", OUT_RESULTS)\n",
    "print(\"Modelos salvos:\")\n",
    "for n, p in model_paths:\n",
    "    print(\" -\", n, \"=>\", p)\n",
    "\n",
    "# ---------- VISÃO (split=teste) ----------\n",
    "cols_show = [\"exp\",\"split\",\"R2_wr_kg_m2_h\",\"MAE_wr_kg_m2_h\",\"R2_wm_kg_m2_h\",\"MAE_wm_kg_m2_h\"]\n",
    "print(\"\\n== COMPARATIVO (split=teste) ==\")\n",
    "display(res[res[\"split\"]==\"teste\"][cols_show].sort_values(\"R2_wm_kg_m2_h\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2978239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MVP fixado.\n",
      "Modelo: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\mvp\\model_mvp.joblib\n",
      "Manifesto: C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\\models\\mvp\\manifest_mvp.json\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# PIN & PACKAGE — MVP = E0_baseline_RF\n",
    "# ============================\n",
    "import os, glob, json, shutil, joblib, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "MODELS_DIR = os.path.join(FREEZE_DIR, \"models\")\n",
    "RESULTS_CSV = os.path.join(FREEZE_DIR, \"experiments_unsup_guided_results.csv\")\n",
    "\n",
    "# 1) Descobrir o melhor E0 salvo (mais recente)\n",
    "cands = glob.glob(os.path.join(MODELS_DIR, \"E0_baseline_RF_*.joblib\"))\n",
    "assert cands, \"Nenhum modelo E0_baseline_RF_*.joblib encontrado. Reexecute a etapa E0.\"\n",
    "cands.sort(key=os.path.getmtime, reverse=True)\n",
    "best_model_path = cands[0]\n",
    "pack = joblib.load(best_model_path)\n",
    "\n",
    "# 2) Ler métricas de TESTE do E0 no CSV\n",
    "res = pd.read_csv(RESULTS_CSV)\n",
    "row = res[(res[\"exp\"]==\"E0_baseline_RF\") & (res[\"split\"]==\"teste\")].iloc[0].to_dict()\n",
    "\n",
    "# 3) Criar pasta MVP e copiar artefato\n",
    "MVP_DIR = os.path.join(MODELS_DIR, \"mvp\")\n",
    "os.makedirs(MVP_DIR, exist_ok=True)\n",
    "mvp_model_path = os.path.join(MVP_DIR, \"model_mvp.joblib\")\n",
    "shutil.copy2(best_model_path, mvp_model_path)\n",
    "\n",
    "# 4) Manifesto do MVP\n",
    "manifest = {\n",
    "    \"tag\": \"MVP_E0_baseline_RF\",\n",
    "    \"created_at\": datetime.now().isoformat(),\n",
    "    \"source_model\": os.path.basename(best_model_path),\n",
    "    \"freeze_dir\": FREEZE_DIR,\n",
    "    \"y_names\": pack.get(\"y_names\", [\"wr_kg_m2_h\",\"wm_kg_m2_h\"]),\n",
    "    \"n_features\": len(pack.get(\"features\", [])),\n",
    "    \"features\": pack.get(\"features\", []),  # pode ser grande; deixe se quiser auditar\n",
    "    \"test_metrics\": {\n",
    "        \"R2_wr\": float(row[\"R2_wr_kg_m2_h\"]),\n",
    "        \"MAE_wr\": float(row[\"MAE_wr_kg_m2_h\"]),\n",
    "        \"R2_wm\": float(row[\"R2_wm_kg_m2_h\"]),\n",
    "        \"MAE_wm\": float(row[\"MAE_wm_kg_m2_h\"]),\n",
    "    }\n",
    "}\n",
    "manifest_path = os.path.join(MVP_DIR, \"manifest_mvp.json\")\n",
    "with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(manifest, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ MVP fixado.\")\n",
    "print(\"Modelo:\", mvp_model_path)\n",
    "print(\"Manifesto:\", manifest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8c85d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# INFERÊNCIA — usando o MVP (E0 baseline)\n",
    "# ============================\n",
    "import os, joblib, numpy as np, pandas as pd\n",
    "\n",
    "FREEZE_DIR = r\"C:\\Users\\wilso\\MBA_EMPREENDEDORISMO\\3AGD\\A1_LOCAL_REFAZIMENTO\\outputs\\freeze\\v1_20250818_0635\"\n",
    "MVP_MODEL = os.path.join(FREEZE_DIR, \"models\", \"mvp\", \"model_mvp.joblib\")\n",
    "\n",
    "def predict_mvp(df_raw: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    df_raw: DataFrame com as MESMAS colunas de nomes (linha 1 do CSV de features),\n",
    "            incluindo a 1ª coluna temporal. O loader interno remove os alvos se presentes.\n",
    "    Retorna: DataFrame com y_pred e, se existirem, y_true + erro.\n",
    "    \"\"\"\n",
    "    pack = joblib.load(MVP_MODEL)\n",
    "    model, imp, sc = pack[\"model\"], pack[\"imputer\"], pack[\"scaler\"]\n",
    "    feat_train = pack.get(\"features\", None)\n",
    "    y_names = pack.get(\"y_names\", [\"wr_kg_m2_h\",\"wm_kg_m2_h\"])\n",
    "\n",
    "    # Se vier CSV com 2 cabeçalhos, reduza antes: df.columns = [c for (c,_) in dfr.columns]\n",
    "    df = df_raw.copy()\n",
    "    if isinstance(df.columns[0], tuple):\n",
    "        df.columns = [c for (c,_) in df.columns]\n",
    "\n",
    "    # Remove alvos se vierem\n",
    "    for y in y_names:\n",
    "        if y in df.columns:\n",
    "            df.drop(columns=[y], inplace=True)\n",
    "\n",
    "    # Seleciona apenas numéricas\n",
    "    X = df.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Alinha às features de treino (ordem/colunas)\n",
    "    if feat_train is not None and len(feat_train) > 0:\n",
    "        # cria colunas ausentes com NaN e reordena\n",
    "        for c in feat_train:\n",
    "            if c not in X.columns:\n",
    "                X[c] = np.nan\n",
    "        X = X[feat_train]\n",
    "    # transforma\n",
    "    Xp = sc.transform(imp.transform(X.values))\n",
    "\n",
    "    # pred\n",
    "    yhat = model.predict(Xp)\n",
    "    out = pd.DataFrame(yhat, columns=[f\"{y}_pred\" for y in y_names])\n",
    "\n",
    "    # se y_true existir no df_raw, calcula erros\n",
    "    have_true = True\n",
    "    for y in y_names:\n",
    "        if y not in df_raw.columns:\n",
    "            have_true = False\n",
    "            break\n",
    "    if have_true:\n",
    "        for y in y_names:\n",
    "            out[f\"{y}_true\"] = pd.to_numeric(df_raw[y], errors=\"coerce\").values\n",
    "            out[f\"{y}_err\"]  = out[f\"{y}_true\"] - out[f\"{y}_pred\"]\n",
    "\n",
    "    return out\n",
    "\n",
    "# EXEMPLO DE USO (comentado):\n",
    "# dfr = pd.read_csv(os.path.join(FREEZE_DIR, \"A1_ML_DL_features_v4_gold.csv\"), header=[0,1], engine=\"python\")\n",
    "# df  = dfr.copy(); df.columns = [c for (c,_) in dfr.columns]\n",
    "# preds = predict_mvp(df.head(100))\n",
    "# preds.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
